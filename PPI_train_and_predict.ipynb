{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_kx98d7P2_tq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kx98d7P2_tq",
        "outputId": "40e1135f-1107-47a8-93ec-90588ffadfa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PUfhF0284hlY",
      "metadata": {
        "id": "PUfhF0284hlY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DefaultConfig(object):\n",
        "\n",
        "    acid_one_hot = [0 for i in range(20)]\n",
        "    acid_idex = {j:i for i,j in enumerate(\"ACDEFGHIKLMNPQRSTVWY\")}\n",
        "\n",
        "\n",
        "    BASE_PATH = \"/content/drive/MyDrive/DeepPPISP-master\"\n",
        "    sequence_path = \"{0}/data_cache/sequence_data\".format(BASE_PATH)\n",
        "    pssm_path = \"{0}/data_cache/pssm_data\".format(BASE_PATH)\n",
        "    dssp_path = \"{0}/data_cache/dssp_data\".format(BASE_PATH)\n",
        "\n",
        "    max_sequence_length = 500\n",
        "    windows_size = 3\n",
        "\n",
        "    batch_size = 32\n",
        "    seq_dim = 20\n",
        "    dssp_dim = 9\n",
        "    pssm_dim = 20\n",
        "\n",
        "    kernels = [13,15,17]\n",
        "    dropout =0.2\n",
        "    splite_rate = 0.9\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-2XS1x6yOB-I",
      "metadata": {
        "id": "-2XS1x6yOB-I"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import torch as t\n",
        "import numpy as np\n",
        "from torch.utils import data\n",
        "\n",
        "\n",
        "class dataSet(data.Dataset):\n",
        "    def __init__(self,window_size,sequences_file=None,pssm_file=None, dssp_file=None, label_file=None, protein_list_file=None):\n",
        "        super(dataSet,self).__init__()\n",
        "\n",
        "        self.all_sequences = []\n",
        "        for seq_file in sequences_file:\n",
        "            with open(seq_file,\"rb\") as fp_seq:\n",
        "               temp_seq  = pickle.load(fp_seq)\n",
        "            self.all_sequences.extend(temp_seq)\n",
        "\n",
        "        self.all_pssm = []\n",
        "        for pm_file in pssm_file:\n",
        "            with open(pm_file,\"rb\") as fp_pssm:\n",
        "                temp_pssm = pickle.load(fp_pssm)\n",
        "            self.all_pssm.extend(temp_pssm)\n",
        "\n",
        "        self.all_dssp = []\n",
        "        for dp_file in dssp_file:\n",
        "            with open(dp_file,\"rb\") as fp_dssp:\n",
        "                temp_dssp  = pickle.load(fp_dssp)\n",
        "            self.all_dssp.extend(temp_dssp)\n",
        "\n",
        "        self.all_label = []\n",
        "        for lab_file in label_file:\n",
        "            with open(lab_file, \"rb\") as fp_label:\n",
        "                temp_label = pickle.load(fp_label)\n",
        "            self.all_label.extend(temp_label)\n",
        "\n",
        "        with open(protein_list_file, \"rb\") as list_label:\n",
        "            self.protein_list = pickle.load(list_label)\n",
        "\n",
        "\n",
        "\n",
        "        self.Config = DefaultConfig()\n",
        "        self.max_seq_len = self.Config.max_sequence_length\n",
        "        self.window_size = window_size\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "\n",
        "        count,id_idx,ii,dset,protein_id,seq_length = self.protein_list[index]\n",
        "        window_size = self.window_size\n",
        "        id_idx = int(id_idx)\n",
        "        win_start = ii - window_size\n",
        "        win_end = ii + window_size\n",
        "        seq_length = int(seq_length)\n",
        "        label_idx = (win_start+win_end)//2\n",
        "\n",
        "        all_seq_features = []\n",
        "        seq_len = 0\n",
        "        for idx in self.all_sequences[id_idx][:self.max_seq_len]:\n",
        "            acid_one_hot = [0 for i in range(20)]\n",
        "            acid_one_hot[idx] = 1\n",
        "            all_seq_features.append(acid_one_hot)\n",
        "            seq_len += 1\n",
        "        while seq_len<self.max_seq_len:\n",
        "            acid_one_hot = [0 for i in range(20)]\n",
        "            all_seq_features.append(acid_one_hot)\n",
        "            seq_len += 1\n",
        "\n",
        "        all_pssm_features = self.all_pssm[id_idx][:self.max_seq_len]\n",
        "        seq_len = len(all_pssm_features)\n",
        "        while seq_len<self.max_seq_len:\n",
        "            zero_vector = [0 for i in range(20)]\n",
        "            all_pssm_features.append(zero_vector)\n",
        "            seq_len += 1\n",
        "\n",
        "        all_dssp_features = self.all_dssp[id_idx][:self.max_seq_len]\n",
        "        seq_len = len(all_dssp_features)\n",
        "        while seq_len<self.max_seq_len:\n",
        "            zero_vector = [0 for i in range(9)]\n",
        "            all_dssp_features.append(zero_vector)\n",
        "            seq_len += 1\n",
        "\n",
        "\n",
        "        local_features = []\n",
        "        labels = []\n",
        "        while win_start<0:\n",
        "            data = []\n",
        "            acid_one_hot = [0 for i in range(20)]\n",
        "            data.extend(acid_one_hot)\n",
        "\n",
        "            pssm_zero_vector = [0 for i in range(20)]\n",
        "            data.extend(pssm_zero_vector)\n",
        "\n",
        "            dssp_zero_vector = [0 for i in range(9)]\n",
        "            data.extend(dssp_zero_vector)\n",
        "\n",
        "            local_features.extend(data)\n",
        "            win_start += 1\n",
        "\n",
        "        valid_end = min(win_end,seq_length-1)\n",
        "        while win_start<=valid_end:\n",
        "            data = []\n",
        "            idx = self.all_sequences[id_idx][win_start]\n",
        "\n",
        "            acid_one_hot = [0 for i in range(20)]\n",
        "            acid_one_hot[idx] = 1\n",
        "            data.extend(acid_one_hot)\n",
        "\n",
        "\n",
        "            pssm_val = self.all_pssm[id_idx][win_start]\n",
        "            data.extend(pssm_val)\n",
        "\n",
        "            try:\n",
        "                dssp_val = self.all_dssp[id_idx][win_start]\n",
        "            except:\n",
        "                dssp_val = [0 for i in range(9)]\n",
        "            data.extend(dssp_val)\n",
        "\n",
        "            local_features.extend(data)\n",
        "            win_start += 1\n",
        "\n",
        "        while win_start<=win_end:\n",
        "            data = []\n",
        "            acid_one_hot = [0 for i in range(20)]\n",
        "            data.extend(acid_one_hot)\n",
        "\n",
        "            pssm_zero_vector = [0 for i in range(20)]\n",
        "            data.extend(pssm_zero_vector)\n",
        "\n",
        "            dssp_zero_vector = [0 for i in range(9)]\n",
        "            data.extend(dssp_zero_vector)\n",
        "\n",
        "            local_features.extend(data)\n",
        "            win_start += 1\n",
        "\n",
        "\n",
        "        label = self.all_label[id_idx][label_idx]\n",
        "        label = np.array(label,dtype=np.float32)\n",
        "\n",
        "        all_seq_features = np.stack(all_seq_features)\n",
        "        all_seq_features = all_seq_features[np.newaxis,:,:]\n",
        "        all_pssm_features = np.stack(all_pssm_features)\n",
        "        all_pssm_features = all_pssm_features[np.newaxis,:,:]\n",
        "\n",
        "        all_dssp_features = np.stack(all_dssp_features)\n",
        "        all_dssp_features = all_dssp_features[np.newaxis,:,:]\n",
        "        local_features = np.stack(local_features)\n",
        "\n",
        "\n",
        "        return all_seq_features,all_pssm_features,all_dssp_features,local_features,label\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.protein_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HjOZGl6238ec",
      "metadata": {
        "id": "HjOZGl6238ec"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch as t\n",
        "import time\n",
        "\n",
        "class BasicModule(t.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BasicModule,self).__init__()\n",
        "        self.model_name = str(type(self))\n",
        "\n",
        "    def load(self,path):\n",
        "\n",
        "        self.load_state_dict(t.load(path))\n",
        "\n",
        "    def save(self,name=None):\n",
        "\n",
        "\n",
        "        if name is None:\n",
        "            prefix = \"\"\n",
        "            name = time.strftime(\"%y%m%d_%H:%M:%S.pth\".format(prefix))\n",
        "\n",
        "        t.save(self.state_dict(),name)\n",
        "        return name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wnWtD6JK3yXo",
      "metadata": {
        "id": "wnWtD6JK3yXo"
      },
      "outputs": [],
      "source": [
        "#-*- encoding:utf8 -*-\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import torch as t\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "# from utils.config import DefaultConfig\n",
        "configs = DefaultConfig()\n",
        "\n",
        "\n",
        "class ConvsLayer(BasicModule):\n",
        "    def __init__(self,):\n",
        "\n",
        "        super(ConvsLayer,self).__init__()\n",
        "\n",
        "        self.kernels = configs.kernels\n",
        "        hidden_channels = configs.cnn_chanel\n",
        "        in_channel = 1\n",
        "        features_L = configs.max_sequence_length\n",
        "        seq_dim = configs.seq_dim\n",
        "        dssp_dim = configs.dssp_dim\n",
        "        pssm_dim = configs.pssm_dim\n",
        "        W_size = seq_dim + dssp_dim + pssm_dim\n",
        "\n",
        "        padding1 = (self.kernels[0]-1)//2\n",
        "        padding2 = (self.kernels[1]-1)//2\n",
        "        padding3 = (self.kernels[2]-1)//2\n",
        "        self.conv1 = nn.Sequential()\n",
        "        self.conv1.add_module(\"conv1\",\n",
        "            nn.Conv2d(in_channel, hidden_channels,\n",
        "            padding=(padding1,0),\n",
        "            kernel_size=(self.kernels[0],W_size)))\n",
        "        self.conv1.add_module(\"ReLU\",nn.PReLU())\n",
        "        self.conv1.add_module(\"pooling1\",nn.MaxPool2d(kernel_size=(features_L,1),stride=1))\n",
        "\n",
        "        self.conv2 = nn.Sequential()\n",
        "        self.conv2.add_module(\"conv2\",\n",
        "            nn.Conv2d(in_channel, hidden_channels,\n",
        "            padding=(padding2,0),\n",
        "            kernel_size=(self.kernels[1],W_size)))\n",
        "        self.conv2.add_module(\"ReLU\",nn.ReLU())\n",
        "        self.conv2.add_module(\"pooling2\",nn.MaxPool2d(kernel_size=(features_L,1),stride=1))\n",
        "\n",
        "        self.conv3 = nn.Sequential()\n",
        "        self.conv3.add_module(\"conv3\",\n",
        "            nn.Conv2d(in_channel, hidden_channels,\n",
        "            padding=(padding3,0),\n",
        "            kernel_size=(self.kernels[2],W_size)))\n",
        "        self.conv3.add_module(\"ReLU\",nn.ReLU())\n",
        "        self.conv3.add_module(\"pooling3\",nn.MaxPool2d(kernel_size=(features_L,1),stride=1))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        features1 = self.conv1(x)\n",
        "        features2 = self.conv2(x)\n",
        "        features3 = self.conv3(x)\n",
        "        features = t.cat((features1,features2,features3),1)\n",
        "        shapes = features.data.shape\n",
        "        features = features.view(shapes[0],shapes[1]*shapes[2]*shapes[3])\n",
        "\n",
        "        return features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DeepPPI(BasicModule):\n",
        "    def __init__(self,class_nums,window_size,ratio=None):\n",
        "        super(DeepPPI,self).__init__()\n",
        "        global configs\n",
        "        configs.kernels = [13, 15, 17]\n",
        "        self.dropout = configs.dropout = 0.2\n",
        "\n",
        "        seq_dim = configs.seq_dim*configs.max_sequence_length\n",
        "\n",
        "\n",
        "        self.seq_layers = nn.Sequential()\n",
        "        self.seq_layers.add_module(\"seq_embedding_layer\",\n",
        "        nn.Linear(seq_dim,seq_dim))\n",
        "        self.seq_layers.add_module(\"seq_embedding_ReLU\",\n",
        "        nn.ReLU())\n",
        "\n",
        "\n",
        "        seq_dim = configs.seq_dim\n",
        "        dssp_dim = configs.dssp_dim\n",
        "        pssm_dim = configs.pssm_dim\n",
        "        local_dim = (window_size*2+1)*(pssm_dim+dssp_dim+seq_dim)\n",
        "        if ratio:\n",
        "            configs.cnn_chanel = (local_dim*int(ratio[0]))//(int(ratio[1])*3)\n",
        "        input_dim = configs.cnn_chanel*3+local_dim\n",
        "\n",
        "        self.multi_CNN = nn.Sequential()\n",
        "        self.multi_CNN.add_module(\"layer_convs\",\n",
        "                               ConvsLayer())\n",
        "\n",
        "\n",
        "\n",
        "        self.DNN1 = nn.Sequential()\n",
        "        self.DNN1.add_module(\"DNN_layer1\",\n",
        "                            nn.Linear(input_dim,1024))\n",
        "        self.DNN1.add_module(\"ReLU1\",\n",
        "                            nn.ReLU())\n",
        "        #self.dropout_layer = nn.Dropout(self.dropout)\n",
        "        self.DNN2 = nn.Sequential()\n",
        "        self.DNN2.add_module(\"DNN_layer2\",\n",
        "                            nn.Linear(1024,256))\n",
        "        self.DNN2.add_module(\"ReLU2\",\n",
        "                            nn.ReLU())\n",
        "\n",
        "\n",
        "        self.outLayer = nn.Sequential(\n",
        "            nn.Linear(256, class_nums),\n",
        "            nn.Sigmoid())\n",
        "\n",
        "    def forward(self,seq,dssp,pssm,local_features):\n",
        "        shapes = seq.data.shape\n",
        "        features = seq.view(shapes[0],shapes[1]*shapes[2]*shapes[3])\n",
        "        features = self.seq_layers(features)\n",
        "        features = features.view(shapes[0],shapes[1],shapes[2],shapes[3])\n",
        "\n",
        "        features = t.cat((features,dssp,pssm),3)\n",
        "        features = self.multi_CNN(features)\n",
        "        features = t.cat((features, local_features), 1)\n",
        "        features = self.DNN1(features)\n",
        "        #features =self.dropout_layer(features)\n",
        "        features = self.DNN2(features)\n",
        "        features = self.outLayer(features)\n",
        "\n",
        "        return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZXTJ3hwB43W3",
      "metadata": {
        "id": "ZXTJ3hwB43W3"
      },
      "outputs": [],
      "source": [
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, matthews_corrcoef, precision_recall_curve,accuracy_score\n",
        "\n",
        "\n",
        "def compute_roc(preds, labels):\n",
        "    fpr, tpr, _ = roc_curve(labels.flatten(), preds.flatten())\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    return roc_auc\n",
        "\n",
        "\n",
        "def compute_aupr(preds, labels):\n",
        "    p, r, _ = precision_recall_curve(labels.flatten(), preds.flatten())\n",
        "    aupr = auc(r, p)\n",
        "    return aupr\n",
        "\n",
        "\n",
        "def compute_mcc(preds, labels, threshold=0.5):\n",
        "    preds = preds.astype(np.float64)\n",
        "    labels = labels.astype(np.float64)\n",
        "    mcc = matthews_corrcoef(labels.flatten(), preds.flatten())\n",
        "    return mcc\n",
        "\n",
        "\n",
        "def compute_performance(preds, labels):\n",
        "\n",
        "    predictions_max = None\n",
        "    f_max = 0\n",
        "    p_max = 0\n",
        "    r_max = 0\n",
        "    t_max = 0\n",
        "    for t in range(1, 100):\n",
        "        threshold = t / 100.0\n",
        "        predictions = (preds > threshold).astype(np.int32)\n",
        "        p = 0.0\n",
        "        r = 0.0\n",
        "        total = 0\n",
        "        p_total = 0\n",
        "\n",
        "        tp = np.sum(predictions * labels)\n",
        "        fp = np.sum(predictions) - tp\n",
        "        fn = np.sum(labels) - tp\n",
        "\n",
        "        if tp == 0 and fp == 0 and fn == 0:\n",
        "            continue\n",
        "        total += 1\n",
        "        if tp != 0:\n",
        "            p_total += 1\n",
        "            precision = tp / (1.0 * (tp + fp))\n",
        "            recall = tp / (1.0 * (tp + fn))\n",
        "            p += precision\n",
        "            r += recall\n",
        "\n",
        "        if total > 0 and p_total > 0:\n",
        "            r /= total\n",
        "            p /= p_total\n",
        "            if p + r > 0:\n",
        "                f = 2 * p * r / (p + r)\n",
        "                if f_max < f:\n",
        "                    f_max = f\n",
        "                    p_max = p\n",
        "                    r_max = r\n",
        "                    t_max = threshold\n",
        "                    predictions_max = predictions\n",
        "\n",
        "    return f_max, p_max, r_max, t_max, predictions_max\n",
        "\n",
        "\n",
        "def micro_score(output, label):\n",
        "    N = len(output)\n",
        "    total_P = np.sum(output)\n",
        "    total_R = np.sum(label)\n",
        "    TP = float(np.sum(output * label))\n",
        "    MiP = TP / max(total_P, 1e-12)\n",
        "    MiR = TP / max(total_R, 1e-12)\n",
        "    if TP==0:\n",
        "        MiF = 0\n",
        "    else:\n",
        "        MiF = 2 * MiP * MiR / (MiP + MiR)\n",
        "    return MiP, MiR, MiF, total_P / N, total_R / N\n",
        "\n",
        "def acc_score(output,label):\n",
        "    acc = accuracy_score(label.flatten(), output.flatten())\n",
        "\n",
        "    return acc\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kH4AMgPVoveY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "kH4AMgPVoveY",
        "outputId": "08392d1c-6d39-4c9b-9827-32cc1a8cc32e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepPPISP-master/data_cache/testing_list.pkl\n",
            "Started\n",
            "Data saved to train_data.pickle\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Please reshape the input data into 2-dimensional matrix.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-6a4df503dcd8>\u001b[0m in \u001b[0;36m<cell line: 418>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-6a4df503dcd8>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(train_data, save, train_num, ratio, window_size, splite_rate, efficient, epochs, seed, pretrained_result)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     train(train_data,model=model, train_data_set=train_dataSet, save=save,\n\u001b[0m\u001b[1;32m    414\u001b[0m           \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m           train_file=train_list_file)\n",
            "\u001b[0;32m<ipython-input-7-6a4df503dcd8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(class_tag, model, train_data_set, save, n_epochs, batch_size, lr, wd, momentum, seed, num, train_file)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# Set XGBoost parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m         handle, feature_names, feature_types = dispatch_data_backend(\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_split_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_from_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_list\u001b[0;34m(data, missing, n_threads, feature_names, feature_types)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m     \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_from_numpy_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[1;32m    202\u001b[0m ) -> DispatchedDataBackendReturnType:\n\u001b[1;32m    203\u001b[0m     \u001b[0;34m\"\"\"Initialize data from a 2-D numpy matrix.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_np_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xgboost/data.py\u001b[0m in \u001b[0;36m_check_data_shape\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_data_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please reshape the input data into 2-dimensional matrix.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Please reshape the input data into 2-dimensional matrix."
          ]
        }
      ],
      "source": [
        "#-*- encoding:utf8 -*-\n",
        "\n",
        "import os\n",
        "import time\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef, confusion_matrix\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.init import xavier_normal,xavier_normal_\n",
        "from torch import nn\n",
        "import torch.utils.data.sampler as sampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from imblearn.over_sampling import SMOTENC,SMOTE\n",
        "from sklearn.datasets import make_classification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import gc\n",
        "\n",
        "\n",
        "configs = DefaultConfig()\n",
        "THREADHOLD = 0.2\n",
        "\n",
        "\n",
        "def save_data(class_tag, train_data_set, save,\n",
        "          train_file=None):\n",
        "\n",
        "    class_tag = \"all_dset\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    global THREADHOLD\n",
        "    # # split data\n",
        "    with open(train_file,\"rb\") as fp:\n",
        "        train_list = pickle.load(fp)\n",
        "\n",
        "\n",
        "    samples_num =len(train_list)\n",
        "    split_num = int(configs.splite_rate * samples_num)\n",
        "    data_index = train_list\n",
        "    np.random.shuffle(data_index)\n",
        "    train_index = data_index\n",
        "    train_samples = sampler.SubsetRandomSampler(train_index)\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    test_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/testing_list.pkl'\n",
        "\n",
        "    with open(test_list_file,\"rb\") as fp:\n",
        "        test_indices = pickle.load(fp)\n",
        "\n",
        "    test_features=[]\n",
        "    test_labels=[]\n",
        "    for i in test_indices:\n",
        "      test_features.append((np.concatenate([comp.numpy().ravel() if hasattr(comp, 'numpy') else comp.ravel() for comp in train_data_set[i][:-1]])))\n",
        "      test_features.append(train_data_set[i][-1])\n",
        "\n",
        "    data_dict = {\n",
        "        'test_features': test_features,\n",
        "        'test_labels': test_labels\n",
        "    }\n",
        "\n",
        "    # File path to store the pickle file\n",
        "    file_path = \"test_data.pickle\"\n",
        "\n",
        "    # Dump the data to a pickle file\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(data_dict, f)\n",
        "\n",
        "    print(\"Data saved to\", file_path)\n",
        "\n",
        "\n",
        "    test_features = []\n",
        "    test_labels = []\n",
        "    with open(test_list_file,\"rb\") as fp:\n",
        "        test_list = pickle.load(fp)\n",
        "    # Extract features and labels from the PyTorch dataset\n",
        "    shuffled_array = np.random.permutation(train_index)\n",
        "    train_indices=shuffled_array\n",
        "\n",
        "    cnt=0\n",
        "    train_features=[]\n",
        "    train_labels=[]\n",
        "\n",
        "    # Clear the lists to free up memory\n",
        "    dnn_train_index=[]\n",
        "\n",
        "    for i in train_indices:\n",
        "      if(train_data_set[i][-1]==0 and cnt<32000):\n",
        "        dnn_train_index.append(i)\n",
        "        cnt+=1\n",
        "        train_features.append((np.concatenate([comp.numpy().ravel() if hasattr(comp, 'numpy') else comp.ravel() for comp in train_data_set[i][:-1]])))\n",
        "        train_labels.append(0)\n",
        "      elif(train_data_set[i][-1]==1):\n",
        "        cnc=np.concatenate([comp.numpy().ravel() if hasattr(comp, 'numpy') else comp.ravel() for comp in train_data_set[i][:-1]])\n",
        "        train_features.append(cnc)\n",
        "        train_labels.append(1)\n",
        "        train_features.append(cnc)\n",
        "        train_labels.append(1)\n",
        "        dnn_train_index.append(i)\n",
        "    data_dict = {\n",
        "        'train_features': train_features,\n",
        "        'train_labels': train_labels\n",
        "    }\n",
        "\n",
        "    # File path to store the pickle file\n",
        "    file_path = \"train_data.pickle\"\n",
        "\n",
        "    # Dump the data to a pickle file\n",
        "    with open(file_path, 'wb') as f:\n",
        "        pickle.dump(data_dict, f)\n",
        "\n",
        "    print(\"Data saved to\", file_path)\n",
        "\n",
        "\n",
        "def save_data_demo(train_data,save=None, train_num = 1,\n",
        "    ratio=None,window_size=3,splite_rate = 0.1, efficient=True,\n",
        "              epochs=10, seed=None,pretrained_result=None):\n",
        "\n",
        "    train_sequences_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_sequence_data.pkl'.format(key) for key in train_data]\n",
        "    train_dssp_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_dssp_data.pkl'.format(key) for key in train_data]\n",
        "    train_pssm_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_pssm_data.pkl'.format(key) for key in train_data]\n",
        "    train_label_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_label.pkl'.format(key) for key in train_data]\n",
        "    all_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/all_dset_list.pkl'\n",
        "    train_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/training_list.pkl'\n",
        "\n",
        "    # Datasets\n",
        "    train_dataSet = dataSet(window_size, train_sequences_file, train_pssm_file, train_dssp_file, train_label_file,\n",
        "                                             all_list_file)\n",
        "\n",
        "    # Train the model\n",
        "    save_data(train_data, train_data_set=train_dataSet, save=save,\n",
        "          train_file=train_list_file)\n",
        "    print('Done!')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    ratio_list = (2,1)  #glboal:local\n",
        "    path_dir = \"./checkpoints/deep_ppi_saved_models\"\n",
        "    train_data = [\"dset186\",\"dset164\",\"dset72\"]\n",
        "    if not os.path.exists(path_dir):\n",
        "        os.makedirs(path_dir)\n",
        "\n",
        "    for ii in range(1):\n",
        "        save_data_demo(train_data,path_dir,ii,ratio_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cwJTV-g6PUGu",
      "metadata": {
        "id": "cwJTV-g6PUGu"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef, confusion_matrix,roc_auc_score, average_precision_score\n",
        "from imblearn.over_sampling import SMOTE,SMOTENC,BorderlineSMOTE,ADASYN\n",
        "\n",
        "# Load the data array\n",
        "data_file = 'train_data.pickle'\n",
        "with open(data_file, 'rb') as fp:\n",
        "    train_data = pickle.load(fp)\n",
        "\n",
        "\n",
        "train_features = train_data[\"train_features\"]\n",
        "train_labels = train_data[\"train_labels\"]\n",
        "\n",
        "for i in range(507):\n",
        "  for j in range(i*49,i*49+20):\n",
        "    category_indices.append(j)\n",
        "  for j in range(i*49+40,i*49+49):\n",
        "    category_indices.append(j)\n",
        "smotenc = SMOTENC(sampling_strategy='auto', categorical_features=category_indices, random_state=42)\n",
        "features_resampled, labels_resampled = smotenc.fit_resample(train_features,train_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zl_YoOC6R4m8",
      "metadata": {
        "id": "Zl_YoOC6R4m8"
      },
      "outputs": [],
      "source": [
        "file_path = \"smote_data.pickle\"\n",
        "data_dict={\"train_features\":features_resampled,\n",
        "           \"train_labels\":labels_resampled}\n",
        "    # Dump the data to a pickle file\n",
        "with open(file_path, 'wb') as f:\n",
        "    pickle.dump(data_dict, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-*- encoding:utf8 -*-\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.nn.init import xavier_normal,xavier_normal_\n",
        "from torch import nn\n",
        "import torch.utils.data.sampler as sampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.datasets import make_classification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import gc\n",
        "\n",
        "\n",
        "configs = DefaultConfig()\n",
        "THREADHOLD = 0.2\n",
        "\n",
        "class AverageMeter(object):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def weight_init(m):\n",
        "    if isinstance(m,nn.Conv2d):\n",
        "        xavier_normal_(m.weight.data)\n",
        "    elif isinstance(m,nn.Linear):\n",
        "        xavier_normal_(m.weight.data)\n",
        "\n",
        "\n",
        "def train_epoch(model, loader, optimizer, epoch, all_epochs, print_freq=100):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "\n",
        "    global THREADHOLD\n",
        "    # Model on train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for batch_idx, (seq_data, pssm_data, dssp_data, local_data, label) in enumerate(loader):\n",
        "        # Create vaiables\n",
        "        with torch.no_grad():\n",
        "            seq_var = torch.autograd.Variable(seq_data.float())\n",
        "            pssm_var = torch.autograd.Variable(pssm_data.float())\n",
        "            dssp_var = torch.autograd.Variable(dssp_data.float())\n",
        "            local_var = torch.autograd.Variable(local_data.float())\n",
        "            target_var = torch.autograd.Variable(label.float())\n",
        "\n",
        "        # compute output\n",
        "        output = model(seq_var, dssp_var, pssm_var, local_var)\n",
        "        shapes = output.data.shape\n",
        "        output = output.view(shapes[0]*shapes[1])\n",
        "        loss = torch.nn.functional.binary_cross_entropy(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        batch_size = label.size(0)\n",
        "        pred_out = output.ge(THREADHOLD)\n",
        "        MiP, MiR, MiF, PNum, RNum = micro_score(pred_out.data.cpu().numpy(),\n",
        "                                                target_var.data.cpu().numpy())\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # print stats\n",
        "        if batch_idx % print_freq == 0:\n",
        "            res = '\\t'.join([\n",
        "                'Epoch: [%d/%d]' % (epoch + 1, all_epochs),\n",
        "                'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
        "                'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
        "                'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
        "                'f_max:%.6f' % (MiP),\n",
        "                'p_max:%.6f' % (MiR),\n",
        "                'r_max:%.6f' % (MiF),\n",
        "                't_max:%.2f' % (PNum)])\n",
        "            print(res)\n",
        "\n",
        "    return batch_time.avg, losses.avg\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader, print_freq=10, is_test=True):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    error = AverageMeter()\n",
        "\n",
        "    global THREADHOLD\n",
        "    # Model on eval mode\n",
        "    model.eval()\n",
        "\n",
        "    all_trues = []\n",
        "    all_preds = []\n",
        "    all_gos = []\n",
        "    end = time.time()\n",
        "    for batch_idx, (seq_data, pssm_data, dssp_data, local_data, label) in enumerate(loader):\n",
        "\n",
        "        # Create vaiables\n",
        "        with torch.no_grad():\n",
        "\n",
        "            seq_var = torch.autograd.Variable(seq_data.float())\n",
        "            pssm_var = torch.autograd.Variable(pssm_data.float())\n",
        "            dssp_var = torch.autograd.Variable(dssp_data.float())\n",
        "            local_var = torch.autograd.Variable(local_data.float())\n",
        "            target_var = torch.autograd.Variable(label.float())\n",
        "\n",
        "        # compute output\n",
        "        output =  model(seq_var, dssp_var, pssm_var, local_var)\n",
        "        shapes = output.data.shape\n",
        "        output = output.view(shapes[0]*shapes[1])\n",
        "\n",
        "        loss = torch.nn.functional.binary_cross_entropy(output, target_var)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        batch_size = label.size(0)\n",
        "        losses.update(loss.item(), batch_size)\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # print stats\n",
        "        if batch_idx % print_freq == 0:\n",
        "            res = '\\t'.join([\n",
        "                'Test' if is_test else 'Valid',\n",
        "                'Iter: [%d/%d]' % (batch_idx + 1, len(loader)),\n",
        "                'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
        "                'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
        "            ])\n",
        "            print(res)\n",
        "        all_trues.append(label.numpy())\n",
        "        all_preds.append(output.data.cpu().numpy())\n",
        "\n",
        "    all_trues = np.concatenate(all_trues, axis=0)\n",
        "    all_preds = np.concatenate(all_preds, axis=0)\n",
        "\n",
        "    auc = compute_roc(all_preds, all_trues)\n",
        "    aupr = compute_aupr(all_preds, all_trues)\n",
        "    f_max, p_max, r_max, t_max, predictions_max = compute_performance(all_preds,all_trues)\n",
        "    acc_val = acc_score(predictions_max,all_trues)\n",
        "    mcc = compute_mcc(predictions_max, all_trues)\n",
        "    return batch_time.avg, losses.avg, acc_val, f_max, p_max, r_max, auc, aupr,t_max, mcc\n",
        "\n",
        "\n",
        "def train(class_tag,model, train_data_set, save, n_epochs=3,\n",
        "          batch_size=64, lr=0.001, wd=0.0001, momentum=0.9, seed=None, num=1,\n",
        "          train_file=None):\n",
        "\n",
        "    class_tag = \"all_dset\"\n",
        "    if seed is not None:\n",
        "        torch.manual_seed(seed)\n",
        "    global THREADHOLD\n",
        "    # split data\n",
        "    with open(train_file,\"rb\") as fp:\n",
        "        train_list = pickle.load(fp)\n",
        "\n",
        "\n",
        "    samples_num =len(train_list)\n",
        "    split_num = int(configs.splite_rate * samples_num)\n",
        "    data_index = train_list\n",
        "    np.random.shuffle(data_index)\n",
        "    train_index = data_index[:split_num]\n",
        "    eval_index = data_index[split_num:]\n",
        "\n",
        "    with open(\"smote_data.pickle\",\"rb\") as fp:\n",
        "        train_data_smote = pickle.load(fp)\n",
        "\n",
        "    dim1 = 500  # Number of elements in the first dimension of each sub-array\n",
        "    dim2 = 20  # Number of elements in the second dimension of the first and second sub-arrays\n",
        "    dim3 = 9  # Number of elements in the second dimension of the third sub-array\n",
        "    features_resampled=train_data_smote[\"train_features\"]\n",
        "    labels_resampled=train_data_smote[\"train_labels\"]\n",
        "    smote_features=[]\n",
        "    for i in range(len(features_resampled)):\n",
        "      feature_reshaped=np.array(features_resampled[i])\n",
        "      smote_features.append((\n",
        "        feature_reshaped[:dim1 * dim2].reshape(1, dim1, dim2),  # First sub-array\n",
        "        feature_reshaped[dim1 * dim2:2 * dim1 * dim2].reshape(1, dim1, dim2),  # Second sub-array\n",
        "        feature_reshaped[2 * dim1 * dim2:2 * dim1 * dim2 + dim1 * dim3].reshape(1, dim1, dim3),  # Third sub-array\n",
        "        feature_reshaped[2 * dim1 * dim2 + dim1 * dim3:].reshape(343),\n",
        "        labels_resampled[i]# Fourth sub-array\n",
        "    ))\n",
        "\n",
        "    #. . . . . . . . . . . . . . . . . .\n",
        "    test_sequences_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_sequence_data.pkl'.format(key) for key in train_data]\n",
        "    test_dssp_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_dssp_data.pkl'.format(key) for key in train_data]\n",
        "    test_pssm_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_pssm_data.pkl'.format(key) for key in train_data]\n",
        "    test_label_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_label.pkl'.format(key) for key in train_data]\n",
        "    all_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/all_dset_list.pkl'\n",
        "    test_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/testing_list.pkl'\n",
        "\n",
        "    batch_size = configs.batch_size\n",
        "\n",
        "    print(test_list_file)\n",
        "\n",
        "    batch_size = configs.batch_size\n",
        "\n",
        "\n",
        "    test_dataSet = dataSet(3, test_sequences_file, test_pssm_file, test_dssp_file, test_label_file,\n",
        "                                             all_list_file)\n",
        "\n",
        "\n",
        "\n",
        "    with open(test_list_file,\"rb\") as fp:\n",
        "        test_list = pickle.load(fp)\n",
        "\n",
        "    print(len(test_list))\n",
        "    test_samples = sampler.SubsetRandomSampler(test_list)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    train_list=[]\n",
        "    for i in range(len(smote_features)):\n",
        "        train_list.append(i)\n",
        "    np.random.shuffle(train_list)\n",
        "    train_index=train_list\n",
        "    train_samples = sampler.SubsetRandomSampler(train_index)\n",
        "    eval_samples = sampler.SubsetRandomSampler(eval_index)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(smote_features, batch_size=batch_size,\n",
        "                                               sampler=train_samples,num_workers=5, drop_last=False)\n",
        "    valid_loader = torch.utils.data.DataLoader(test_dataSet, batch_size=batch_size,sampler=test_samples,num_workers=5, drop_last=False)\n",
        "\n",
        "\n",
        "\n",
        "    # Wrap model for multi-GPUs, if necessary\n",
        "    model_wrapper = model\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(model_wrapper.parameters(), lr=0.001)\n",
        "\n",
        "    # Start log\n",
        "    with open(os.path.join(save, 'DeepPPI_results.csv'), 'w') as f:\n",
        "        f.write('epoch,loss,acc,F_value, precision,recall,auc,aupr,mcc,threadhold\\n')\n",
        "\n",
        "        # Train model\n",
        "        best_F = 0\n",
        "        threadhold = 0\n",
        "        count = 0\n",
        "        for epoch in range(n_epochs):\n",
        "            _, train_loss = train_epoch(\n",
        "                model=model_wrapper,\n",
        "                loader=train_loader,\n",
        "                optimizer=optimizer,\n",
        "                epoch=epoch,\n",
        "                all_epochs=n_epochs,\n",
        "            )\n",
        "            _, valid_loss, acc, f_max, p_max, r_max, auc, aupr,t_max,mcc= eval_epoch(\n",
        "                model=model_wrapper,\n",
        "                loader=valid_loader,\n",
        "                is_test=(not valid_loader)\n",
        "            )\n",
        "\n",
        "            print(\n",
        "            'epoch:%03d,valid_loss:%0.5f\\nacc:%0.6f,F_value:%0.6f, precision:%0.6f,recall:%0.6f,auc:%0.6f,aupr:%0.6f,mcc:%0.6f,threadhold:%0.6f\\n' % ((epoch + 1), valid_loss, acc, f_max, p_max, r_max,auc, aupr,mcc,t_max))\n",
        "            if f_max > best_F:\n",
        "                count = 0\n",
        "                best_F = f_max\n",
        "                THREADHOLD = t_max\n",
        "                print(\"new best F_value:{0}(threadhold:{1})\".format(f_max, THREADHOLD))\n",
        "                torch.save(model.state_dict(), os.path.join(save, 'DeepPPI_model.dat'))\n",
        "            else:\n",
        "                count += 1\n",
        "                if count>=5:\n",
        "                    return None\n",
        "            # Log results\n",
        "            f.write('%03d,%0.6f,%0.6f,%0.6f,%0.6f,%0.6f,%0.6f,%0.6f,%0.6f,%0.6f\\n' % ((epoch + 1), valid_loss, acc, f_max, p_max, r_max, auc, aupr,mcc,t_max))\n",
        "\n",
        "\n",
        "\n",
        "def demo(train_data,save=None, train_num = 1,\n",
        "    ratio=None,window_size=3,splite_rate = 0.1, efficient=True,\n",
        "              epochs=10, seed=None,pretrained_result=None):\n",
        "\n",
        "    train_sequences_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_sequence_data.pkl'.format(key) for key in train_data]\n",
        "    train_dssp_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_dssp_data.pkl'.format(key) for key in train_data]\n",
        "    train_pssm_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_pssm_data.pkl'.format(key) for key in train_data]\n",
        "    train_label_file = ['/content/drive/MyDrive/DeepPPISP-master/data_cache/{0}_label.pkl'.format(key) for key in train_data]\n",
        "    all_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/all_dset_list.pkl'\n",
        "    train_list_file = '/content/drive/MyDrive/DeepPPISP-master/data_cache/training_list.pkl'\n",
        "\n",
        "\n",
        "    #parameters\n",
        "    batch_size = configs.batch_size\n",
        "\n",
        "    # Datasets\n",
        "    train_dataSet = dataSet(window_size, train_sequences_file, train_pssm_file, train_dssp_file, train_label_file,\n",
        "                                             all_list_file)\n",
        "    # Models\n",
        "\n",
        "    class_nums = 1\n",
        "    model = DeepPPI(class_nums,window_size,ratio)\n",
        "    model.apply(weight_init)\n",
        "\n",
        "    # Train the model\n",
        "    train(train_data,model=model, train_data_set=train_dataSet, save=save,\n",
        "          n_epochs=epochs, batch_size=batch_size, seed=seed,num=train_num,\n",
        "          train_file=train_list_file)\n",
        "    print('Done!')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    ratio_list = (2,1)  #glboal:local\n",
        "    path_dir = \"./checkpoints/deep_ppi_saved_models\"\n",
        "    train_data = [\"dset186\",\"dset164\",\"dset72\"]\n",
        "    if not os.path.exists(path_dir):\n",
        "        os.makedirs(path_dir)\n",
        "\n",
        "    for ii in range(1):\n",
        "        demo(train_data,path_dir,ii,ratio_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fqGrAAd1hywX",
        "outputId": "a2dc52f9-fa66-4fdc-9278-22303f279a02"
      },
      "id": "fqGrAAd1hywX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DeepPPISP-master/data_cache/testing_list.pkl\n",
            "11791\n",
            "Epoch: [1/10]\tIter: [1/2045]\tTime 9.403 (9.403)\tLoss 0.7997 (0.7997)\tf_max:0.666667\tp_max:0.666667\tr_max:0.666667\tt_max:0.47\n",
            "Epoch: [1/10]\tIter: [101/2045]\tTime 0.917 (1.036)\tLoss 0.6934 (0.8831)\tf_max:0.448276\tp_max:1.000000\tr_max:0.619048\tt_max:0.91\n",
            "Epoch: [1/10]\tIter: [201/2045]\tTime 0.876 (0.980)\tLoss 0.6695 (0.7771)\tf_max:0.437500\tp_max:1.000000\tr_max:0.608696\tt_max:1.00\n",
            "Epoch: [1/10]\tIter: [301/2045]\tTime 0.879 (0.965)\tLoss 0.6644 (0.7386)\tf_max:0.500000\tp_max:1.000000\tr_max:0.666667\tt_max:1.00\n",
            "Epoch: [1/10]\tIter: [401/2045]\tTime 0.924 (0.956)\tLoss 0.5739 (0.7122)\tf_max:0.629630\tp_max:1.000000\tr_max:0.772727\tt_max:0.84\n",
            "Epoch: [1/10]\tIter: [501/2045]\tTime 0.882 (0.950)\tLoss 0.6332 (0.6947)\tf_max:0.451613\tp_max:1.000000\tr_max:0.622222\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [601/2045]\tTime 0.923 (0.948)\tLoss 0.6659 (0.6811)\tf_max:0.548387\tp_max:0.944444\tr_max:0.693878\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [701/2045]\tTime 1.131 (0.968)\tLoss 0.5934 (0.6690)\tf_max:0.483871\tp_max:0.937500\tr_max:0.638298\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [801/2045]\tTime 1.150 (0.997)\tLoss 0.5950 (0.6609)\tf_max:0.466667\tp_max:1.000000\tr_max:0.636364\tt_max:0.94\n",
            "Epoch: [1/10]\tIter: [901/2045]\tTime 1.154 (1.020)\tLoss 0.8500 (0.6531)\tf_max:0.437500\tp_max:1.000000\tr_max:0.608696\tt_max:1.00\n",
            "Epoch: [1/10]\tIter: [1001/2045]\tTime 1.160 (1.038)\tLoss 0.6649 (0.6436)\tf_max:0.500000\tp_max:0.800000\tr_max:0.615385\tt_max:0.75\n",
            "Epoch: [1/10]\tIter: [1101/2045]\tTime 1.179 (1.055)\tLoss 0.4550 (0.6358)\tf_max:0.645161\tp_max:1.000000\tr_max:0.784314\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [1201/2045]\tTime 1.250 (1.070)\tLoss 0.4375 (0.6286)\tf_max:0.531250\tp_max:1.000000\tr_max:0.693878\tt_max:1.00\n",
            "Epoch: [1/10]\tIter: [1301/2045]\tTime 1.193 (1.083)\tLoss 0.4724 (0.6216)\tf_max:0.680000\tp_max:0.894737\tr_max:0.772727\tt_max:0.78\n",
            "Epoch: [1/10]\tIter: [1401/2045]\tTime 1.524 (1.096)\tLoss 0.4845 (0.6155)\tf_max:0.566667\tp_max:1.000000\tr_max:0.723404\tt_max:0.94\n",
            "Epoch: [1/10]\tIter: [1501/2045]\tTime 1.194 (1.107)\tLoss 1.0218 (0.6097)\tf_max:0.333333\tp_max:1.000000\tr_max:0.500000\tt_max:0.94\n",
            "Epoch: [1/10]\tIter: [1601/2045]\tTime 1.200 (1.116)\tLoss 0.5449 (0.6040)\tf_max:0.451613\tp_max:1.000000\tr_max:0.622222\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [1701/2045]\tTime 1.203 (1.123)\tLoss 0.5291 (0.5990)\tf_max:0.548387\tp_max:1.000000\tr_max:0.708333\tt_max:0.97\n",
            "Epoch: [1/10]\tIter: [1801/2045]\tTime 1.213 (1.129)\tLoss 0.4754 (0.5949)\tf_max:0.500000\tp_max:1.000000\tr_max:0.666667\tt_max:1.00\n",
            "Epoch: [1/10]\tIter: [1901/2045]\tTime 1.167 (1.135)\tLoss 0.5387 (0.5911)\tf_max:0.533333\tp_max:1.000000\tr_max:0.695652\tt_max:0.94\n",
            "Epoch: [1/10]\tIter: [2001/2045]\tTime 1.399 (1.140)\tLoss 0.5390 (0.5876)\tf_max:0.692308\tp_max:0.947368\tr_max:0.800000\tt_max:0.81\n",
            "Valid\tIter: [1/369]\tTime 1.829 (1.829)\tLoss 0.5246 (0.5246)\n",
            "Valid\tIter: [11/369]\tTime 0.260 (0.409)\tLoss 0.5917 (0.5084)\n",
            "Valid\tIter: [21/369]\tTime 0.283 (0.347)\tLoss 0.5117 (0.5200)\n",
            "Valid\tIter: [31/369]\tTime 0.253 (0.321)\tLoss 0.5184 (0.5038)\n",
            "Valid\tIter: [41/369]\tTime 0.270 (0.308)\tLoss 0.6539 (0.5077)\n",
            "Valid\tIter: [51/369]\tTime 0.271 (0.302)\tLoss 0.4984 (0.5078)\n",
            "Valid\tIter: [61/369]\tTime 0.260 (0.296)\tLoss 0.5675 (0.5083)\n",
            "Valid\tIter: [71/369]\tTime 0.280 (0.293)\tLoss 0.4326 (0.5094)\n",
            "Valid\tIter: [81/369]\tTime 0.269 (0.290)\tLoss 0.6119 (0.5137)\n",
            "Valid\tIter: [91/369]\tTime 0.254 (0.287)\tLoss 0.3598 (0.5109)\n",
            "Valid\tIter: [101/369]\tTime 0.275 (0.285)\tLoss 0.4982 (0.5122)\n",
            "Valid\tIter: [111/369]\tTime 0.284 (0.283)\tLoss 0.4614 (0.5077)\n",
            "Valid\tIter: [121/369]\tTime 0.262 (0.282)\tLoss 0.4880 (0.5080)\n",
            "Valid\tIter: [131/369]\tTime 0.258 (0.281)\tLoss 0.4327 (0.5092)\n",
            "Valid\tIter: [141/369]\tTime 0.256 (0.279)\tLoss 0.4809 (0.5085)\n",
            "Valid\tIter: [151/369]\tTime 0.264 (0.278)\tLoss 0.4900 (0.5085)\n",
            "Valid\tIter: [161/369]\tTime 0.277 (0.278)\tLoss 0.4697 (0.5078)\n",
            "Valid\tIter: [171/369]\tTime 0.267 (0.277)\tLoss 0.5798 (0.5080)\n",
            "Valid\tIter: [181/369]\tTime 0.260 (0.277)\tLoss 0.5929 (0.5106)\n",
            "Valid\tIter: [191/369]\tTime 0.262 (0.276)\tLoss 0.4311 (0.5111)\n",
            "Valid\tIter: [201/369]\tTime 0.268 (0.276)\tLoss 0.5418 (0.5115)\n",
            "Valid\tIter: [211/369]\tTime 0.264 (0.275)\tLoss 0.5014 (0.5129)\n",
            "Valid\tIter: [221/369]\tTime 0.263 (0.275)\tLoss 0.4849 (0.5136)\n",
            "Valid\tIter: [231/369]\tTime 0.266 (0.275)\tLoss 0.4548 (0.5143)\n",
            "Valid\tIter: [241/369]\tTime 0.272 (0.274)\tLoss 0.5230 (0.5135)\n",
            "Valid\tIter: [251/369]\tTime 0.264 (0.274)\tLoss 0.5537 (0.5149)\n",
            "Valid\tIter: [261/369]\tTime 0.262 (0.274)\tLoss 0.4530 (0.5145)\n",
            "Valid\tIter: [271/369]\tTime 0.289 (0.274)\tLoss 0.4921 (0.5140)\n",
            "Valid\tIter: [281/369]\tTime 0.258 (0.274)\tLoss 0.4424 (0.5138)\n",
            "Valid\tIter: [291/369]\tTime 0.271 (0.274)\tLoss 0.5061 (0.5132)\n",
            "Valid\tIter: [301/369]\tTime 0.276 (0.274)\tLoss 0.4912 (0.5123)\n",
            "Valid\tIter: [311/369]\tTime 0.263 (0.274)\tLoss 0.5699 (0.5126)\n",
            "Valid\tIter: [321/369]\tTime 0.266 (0.273)\tLoss 0.5182 (0.5125)\n",
            "Valid\tIter: [331/369]\tTime 0.279 (0.273)\tLoss 0.4237 (0.5121)\n",
            "Valid\tIter: [341/369]\tTime 0.263 (0.273)\tLoss 0.4574 (0.5131)\n",
            "Valid\tIter: [351/369]\tTime 0.282 (0.273)\tLoss 0.5581 (0.5126)\n",
            "Valid\tIter: [361/369]\tTime 0.251 (0.273)\tLoss 0.6121 (0.5128)\n",
            "epoch:001,valid_loss:0.51253\n",
            "acc:0.572640,F_value:0.390910, precision:0.272176,recall:0.693396,auc:0.664882,aupr:0.315908,mcc:0.188226,threadhold:0.310000\n",
            "\n",
            "new best F_value:0.39091018977396347(threadhold:0.31)\n",
            "Epoch: [2/10]\tIter: [1/2045]\tTime 3.411 (3.411)\tLoss 0.5951 (0.5951)\tf_max:0.933333\tp_max:0.636364\tr_max:0.756757\tt_max:0.47\n",
            "Epoch: [2/10]\tIter: [101/2045]\tTime 1.275 (1.242)\tLoss 0.4666 (0.5040)\tf_max:0.764706\tp_max:0.928571\tr_max:0.838710\tt_max:0.53\n",
            "Epoch: [2/10]\tIter: [201/2045]\tTime 1.183 (1.234)\tLoss 0.6695 (0.5018)\tf_max:0.500000\tp_max:0.583333\tr_max:0.538462\tt_max:0.44\n",
            "Epoch: [2/10]\tIter: [301/2045]\tTime 1.200 (1.227)\tLoss 0.4314 (0.5016)\tf_max:0.461538\tp_max:1.000000\tr_max:0.631579\tt_max:0.81\n",
            "Epoch: [2/10]\tIter: [401/2045]\tTime 1.353 (1.228)\tLoss 0.5871 (0.5048)\tf_max:0.666667\tp_max:0.888889\tr_max:0.761905\tt_max:0.75\n",
            "Epoch: [2/10]\tIter: [501/2045]\tTime 1.345 (1.229)\tLoss 0.4050 (0.5017)\tf_max:0.714286\tp_max:0.937500\tr_max:0.810811\tt_max:0.66\n",
            "Epoch: [2/10]\tIter: [601/2045]\tTime 1.187 (1.231)\tLoss 0.4559 (0.5005)\tf_max:0.800000\tp_max:0.952381\tr_max:0.869565\tt_max:0.78\n",
            "Epoch: [2/10]\tIter: [701/2045]\tTime 1.179 (1.232)\tLoss 0.4964 (0.4981)\tf_max:0.727273\tp_max:0.888889\tr_max:0.800000\tt_max:0.69\n",
            "Epoch: [2/10]\tIter: [801/2045]\tTime 1.213 (1.233)\tLoss 0.5078 (0.4948)\tf_max:0.666667\tp_max:0.888889\tr_max:0.761905\tt_max:0.75\n",
            "Epoch: [2/10]\tIter: [901/2045]\tTime 1.563 (1.232)\tLoss 0.5071 (0.4966)\tf_max:0.727273\tp_max:0.888889\tr_max:0.800000\tt_max:0.69\n",
            "Epoch: [2/10]\tIter: [1001/2045]\tTime 1.414 (1.230)\tLoss 0.6341 (0.4957)\tf_max:0.650000\tp_max:0.684211\tr_max:0.666667\tt_max:0.62\n",
            "Epoch: [2/10]\tIter: [1101/2045]\tTime 1.301 (1.231)\tLoss 0.4043 (0.4945)\tf_max:0.821429\tp_max:0.958333\tr_max:0.884615\tt_max:0.88\n",
            "Epoch: [2/10]\tIter: [1201/2045]\tTime 1.203 (1.232)\tLoss 0.4846 (0.4937)\tf_max:0.545455\tp_max:1.000000\tr_max:0.705882\tt_max:0.69\n",
            "Epoch: [2/10]\tIter: [1301/2045]\tTime 1.186 (1.232)\tLoss 0.3839 (0.4932)\tf_max:0.800000\tp_max:1.000000\tr_max:0.888889\tt_max:0.62\n",
            "Epoch: [2/10]\tIter: [1401/2045]\tTime 1.232 (1.232)\tLoss 0.5212 (0.4921)\tf_max:0.619048\tp_max:0.812500\tr_max:0.702703\tt_max:0.66\n",
            "Epoch: [2/10]\tIter: [1501/2045]\tTime 1.246 (1.233)\tLoss 0.4742 (0.4928)\tf_max:0.565217\tp_max:0.928571\tr_max:0.702703\tt_max:0.72\n",
            "Epoch: [2/10]\tIter: [1601/2045]\tTime 1.476 (1.236)\tLoss 0.4015 (0.4920)\tf_max:0.708333\tp_max:0.944444\tr_max:0.809524\tt_max:0.75\n",
            "Epoch: [2/10]\tIter: [1701/2045]\tTime 1.204 (1.238)\tLoss 0.5339 (0.4909)\tf_max:0.666667\tp_max:0.823529\tr_max:0.736842\tt_max:0.66\n",
            "Epoch: [2/10]\tIter: [1801/2045]\tTime 1.224 (1.239)\tLoss 0.4108 (0.4906)\tf_max:0.880000\tp_max:0.916667\tr_max:0.897959\tt_max:0.78\n",
            "Epoch: [2/10]\tIter: [1901/2045]\tTime 1.264 (1.240)\tLoss 0.4008 (0.4893)\tf_max:0.739130\tp_max:1.000000\tr_max:0.850000\tt_max:0.72\n",
            "Epoch: [2/10]\tIter: [2001/2045]\tTime 1.185 (1.241)\tLoss 0.3532 (0.4884)\tf_max:0.714286\tp_max:0.937500\tr_max:0.810811\tt_max:0.66\n",
            "Valid\tIter: [1/369]\tTime 1.881 (1.881)\tLoss 0.5711 (0.5711)\n",
            "Valid\tIter: [11/369]\tTime 0.268 (0.430)\tLoss 0.5908 (0.5948)\n",
            "Valid\tIter: [21/369]\tTime 0.270 (0.352)\tLoss 0.5844 (0.5862)\n",
            "Valid\tIter: [31/369]\tTime 0.267 (0.325)\tLoss 0.7260 (0.5992)\n",
            "Valid\tIter: [41/369]\tTime 0.271 (0.310)\tLoss 0.5642 (0.5993)\n",
            "Valid\tIter: [51/369]\tTime 0.296 (0.305)\tLoss 0.4993 (0.6008)\n",
            "Valid\tIter: [61/369]\tTime 0.268 (0.300)\tLoss 0.6293 (0.6026)\n",
            "Valid\tIter: [71/369]\tTime 0.277 (0.297)\tLoss 0.5934 (0.6023)\n",
            "Valid\tIter: [81/369]\tTime 0.264 (0.293)\tLoss 0.7053 (0.6074)\n",
            "Valid\tIter: [91/369]\tTime 0.279 (0.290)\tLoss 0.6745 (0.6077)\n",
            "Valid\tIter: [101/369]\tTime 0.266 (0.289)\tLoss 0.6023 (0.6100)\n",
            "Valid\tIter: [111/369]\tTime 0.267 (0.287)\tLoss 0.5537 (0.6113)\n",
            "Valid\tIter: [121/369]\tTime 0.265 (0.285)\tLoss 0.5913 (0.6147)\n",
            "Valid\tIter: [131/369]\tTime 0.287 (0.284)\tLoss 0.6572 (0.6187)\n",
            "Valid\tIter: [141/369]\tTime 0.282 (0.283)\tLoss 0.5339 (0.6176)\n",
            "Valid\tIter: [151/369]\tTime 0.276 (0.283)\tLoss 0.6226 (0.6187)\n",
            "Valid\tIter: [161/369]\tTime 0.266 (0.282)\tLoss 0.6621 (0.6183)\n",
            "Valid\tIter: [171/369]\tTime 0.261 (0.281)\tLoss 0.6299 (0.6191)\n",
            "Valid\tIter: [181/369]\tTime 0.272 (0.280)\tLoss 0.5087 (0.6189)\n",
            "Valid\tIter: [191/369]\tTime 0.264 (0.280)\tLoss 0.7583 (0.6219)\n",
            "Valid\tIter: [201/369]\tTime 0.261 (0.280)\tLoss 0.6275 (0.6245)\n",
            "Valid\tIter: [211/369]\tTime 0.275 (0.279)\tLoss 0.5826 (0.6250)\n",
            "Valid\tIter: [221/369]\tTime 0.267 (0.278)\tLoss 0.5851 (0.6249)\n",
            "Valid\tIter: [231/369]\tTime 0.263 (0.278)\tLoss 0.7067 (0.6273)\n",
            "Valid\tIter: [241/369]\tTime 0.274 (0.278)\tLoss 0.6403 (0.6265)\n",
            "Valid\tIter: [251/369]\tTime 0.261 (0.277)\tLoss 0.5666 (0.6260)\n",
            "Valid\tIter: [261/369]\tTime 0.261 (0.277)\tLoss 0.7419 (0.6268)\n",
            "Valid\tIter: [271/369]\tTime 0.256 (0.276)\tLoss 0.5616 (0.6265)\n",
            "Valid\tIter: [281/369]\tTime 0.283 (0.277)\tLoss 0.5951 (0.6275)\n",
            "Valid\tIter: [291/369]\tTime 0.297 (0.276)\tLoss 0.5548 (0.6284)\n",
            "Valid\tIter: [301/369]\tTime 0.283 (0.276)\tLoss 0.6473 (0.6276)\n",
            "Valid\tIter: [311/369]\tTime 7.232 (0.320)\tLoss 0.7227 (0.6265)\n",
            "Valid\tIter: [321/369]\tTime 0.274 (0.318)\tLoss 0.6784 (0.6269)\n",
            "Valid\tIter: [331/369]\tTime 0.270 (0.317)\tLoss 0.6907 (0.6268)\n",
            "Valid\tIter: [341/369]\tTime 0.264 (0.315)\tLoss 0.6412 (0.6269)\n",
            "Valid\tIter: [351/369]\tTime 0.258 (0.314)\tLoss 0.6208 (0.6274)\n",
            "Valid\tIter: [361/369]\tTime 0.269 (0.313)\tLoss 0.7087 (0.6273)\n",
            "epoch:002,valid_loss:0.62739\n",
            "acc:0.578153,F_value:0.386683, precision:0.271374,recall:0.672384,auc:0.660075,aupr:0.314857,mcc:0.181118,threadhold:0.450000\n",
            "\n",
            "Epoch: [3/10]\tIter: [1/2045]\tTime 3.364 (3.364)\tLoss 0.3886 (0.3886)\tf_max:0.590909\tp_max:0.928571\tr_max:0.722222\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [101/2045]\tTime 1.186 (1.264)\tLoss 0.5403 (0.4489)\tf_max:0.578947\tp_max:0.785714\tr_max:0.666667\tt_max:0.59\n",
            "Epoch: [3/10]\tIter: [201/2045]\tTime 1.413 (1.257)\tLoss 0.4973 (0.4595)\tf_max:0.680000\tp_max:0.894737\tr_max:0.772727\tt_max:0.78\n",
            "Epoch: [3/10]\tIter: [301/2045]\tTime 1.173 (1.254)\tLoss 0.4585 (0.4570)\tf_max:0.545455\tp_max:0.923077\tr_max:0.685714\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [401/2045]\tTime 1.188 (1.247)\tLoss 0.3984 (0.4574)\tf_max:0.705882\tp_max:0.857143\tr_max:0.774194\tt_max:0.53\n",
            "Epoch: [3/10]\tIter: [501/2045]\tTime 1.204 (1.243)\tLoss 0.5012 (0.4565)\tf_max:0.545455\tp_max:1.000000\tr_max:0.705882\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [601/2045]\tTime 1.171 (1.239)\tLoss 0.3355 (0.4564)\tf_max:0.636364\tp_max:1.000000\tr_max:0.777778\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [701/2045]\tTime 1.205 (1.236)\tLoss 0.4130 (0.4557)\tf_max:0.708333\tp_max:0.944444\tr_max:0.809524\tt_max:0.75\n",
            "Epoch: [3/10]\tIter: [801/2045]\tTime 1.184 (1.236)\tLoss 0.5676 (0.4552)\tf_max:0.555556\tp_max:0.833333\tr_max:0.666667\tt_max:0.84\n",
            "Epoch: [3/10]\tIter: [901/2045]\tTime 1.256 (1.236)\tLoss 0.3749 (0.4549)\tf_max:0.681818\tp_max:0.882353\tr_max:0.769231\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [1001/2045]\tTime 1.206 (1.237)\tLoss 0.4997 (0.4535)\tf_max:0.636364\tp_max:0.933333\tr_max:0.756757\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [1101/2045]\tTime 1.435 (1.238)\tLoss 0.3916 (0.4535)\tf_max:0.750000\tp_max:0.818182\tr_max:0.782609\tt_max:0.38\n",
            "Epoch: [3/10]\tIter: [1201/2045]\tTime 1.212 (1.240)\tLoss 0.4256 (0.4536)\tf_max:0.466667\tp_max:0.700000\tr_max:0.560000\tt_max:0.47\n",
            "Epoch: [3/10]\tIter: [1301/2045]\tTime 1.203 (1.240)\tLoss 0.5462 (0.4540)\tf_max:0.500000\tp_max:0.769231\tr_max:0.606061\tt_max:0.62\n",
            "Epoch: [3/10]\tIter: [1401/2045]\tTime 1.206 (1.239)\tLoss 0.4402 (0.4533)\tf_max:0.526316\tp_max:0.833333\tr_max:0.645161\tt_max:0.59\n",
            "Epoch: [3/10]\tIter: [1501/2045]\tTime 1.193 (1.239)\tLoss 0.3147 (0.4527)\tf_max:0.739130\tp_max:1.000000\tr_max:0.850000\tt_max:0.72\n",
            "Epoch: [3/10]\tIter: [1601/2045]\tTime 1.189 (1.239)\tLoss 0.4535 (0.4522)\tf_max:0.809524\tp_max:0.894737\tr_max:0.850000\tt_max:0.66\n",
            "Epoch: [3/10]\tIter: [1701/2045]\tTime 1.178 (1.239)\tLoss 0.4938 (0.4527)\tf_max:0.772727\tp_max:0.894737\tr_max:0.829268\tt_max:0.69\n",
            "Epoch: [3/10]\tIter: [1801/2045]\tTime 1.357 (1.239)\tLoss 0.4586 (0.4518)\tf_max:0.678571\tp_max:0.950000\tr_max:0.791667\tt_max:0.88\n",
            "Epoch: [3/10]\tIter: [1901/2045]\tTime 1.195 (1.238)\tLoss 0.3124 (0.4511)\tf_max:0.684211\tp_max:1.000000\tr_max:0.812500\tt_max:0.59\n",
            "Epoch: [3/10]\tIter: [2001/2045]\tTime 1.202 (1.238)\tLoss 0.3026 (0.4503)\tf_max:0.761905\tp_max:1.000000\tr_max:0.864865\tt_max:0.66\n",
            "Valid\tIter: [1/369]\tTime 1.906 (1.906)\tLoss 0.7350 (0.7350)\n",
            "Valid\tIter: [11/369]\tTime 0.264 (0.432)\tLoss 0.8243 (0.6319)\n",
            "Valid\tIter: [21/369]\tTime 0.267 (0.354)\tLoss 0.6307 (0.6081)\n",
            "Valid\tIter: [31/369]\tTime 0.273 (0.328)\tLoss 0.5501 (0.6041)\n",
            "Valid\tIter: [41/369]\tTime 0.290 (0.313)\tLoss 0.6213 (0.5835)\n",
            "Valid\tIter: [51/369]\tTime 0.278 (0.305)\tLoss 0.5992 (0.5912)\n",
            "Valid\tIter: [61/369]\tTime 0.296 (0.301)\tLoss 0.6140 (0.5970)\n",
            "Valid\tIter: [71/369]\tTime 0.272 (0.297)\tLoss 0.5395 (0.6066)\n",
            "Valid\tIter: [81/369]\tTime 0.271 (0.294)\tLoss 0.5717 (0.6094)\n",
            "Valid\tIter: [91/369]\tTime 0.255 (0.291)\tLoss 0.6177 (0.6062)\n",
            "Valid\tIter: [101/369]\tTime 0.256 (0.289)\tLoss 0.6615 (0.6073)\n",
            "Valid\tIter: [111/369]\tTime 0.260 (0.287)\tLoss 0.5262 (0.6024)\n",
            "Valid\tIter: [121/369]\tTime 0.275 (0.285)\tLoss 0.6584 (0.6011)\n",
            "Valid\tIter: [131/369]\tTime 0.265 (0.355)\tLoss 0.6479 (0.6056)\n",
            "Valid\tIter: [141/369]\tTime 0.273 (0.350)\tLoss 0.5312 (0.6052)\n",
            "Valid\tIter: [151/369]\tTime 0.262 (0.344)\tLoss 0.6353 (0.6065)\n",
            "Valid\tIter: [161/369]\tTime 0.287 (0.340)\tLoss 0.5908 (0.6058)\n",
            "Valid\tIter: [171/369]\tTime 0.273 (0.336)\tLoss 0.7098 (0.6083)\n",
            "Valid\tIter: [181/369]\tTime 0.266 (0.332)\tLoss 0.6419 (0.6076)\n",
            "Valid\tIter: [191/369]\tTime 0.267 (0.328)\tLoss 0.6911 (0.6056)\n",
            "Valid\tIter: [201/369]\tTime 0.275 (0.325)\tLoss 0.5507 (0.6042)\n",
            "Valid\tIter: [211/369]\tTime 0.252 (0.322)\tLoss 0.7132 (0.6037)\n",
            "Valid\tIter: [221/369]\tTime 0.264 (0.320)\tLoss 0.7250 (0.6052)\n",
            "Valid\tIter: [231/369]\tTime 0.265 (0.317)\tLoss 0.5322 (0.6030)\n",
            "Valid\tIter: [241/369]\tTime 0.260 (0.315)\tLoss 0.5759 (0.6008)\n",
            "Valid\tIter: [251/369]\tTime 0.275 (0.313)\tLoss 0.5457 (0.6004)\n",
            "Valid\tIter: [261/369]\tTime 0.270 (0.312)\tLoss 0.6201 (0.6008)\n",
            "Valid\tIter: [271/369]\tTime 0.264 (0.310)\tLoss 0.5930 (0.5996)\n",
            "Valid\tIter: [281/369]\tTime 0.270 (0.309)\tLoss 0.5893 (0.5998)\n",
            "Valid\tIter: [291/369]\tTime 0.284 (0.308)\tLoss 0.6199 (0.6007)\n",
            "Valid\tIter: [301/369]\tTime 0.271 (0.306)\tLoss 0.4982 (0.6007)\n",
            "Valid\tIter: [311/369]\tTime 0.263 (0.305)\tLoss 0.7610 (0.6012)\n",
            "Valid\tIter: [321/369]\tTime 0.273 (0.304)\tLoss 0.4496 (0.5997)\n",
            "Valid\tIter: [331/369]\tTime 0.288 (0.303)\tLoss 0.5743 (0.5975)\n",
            "Valid\tIter: [341/369]\tTime 0.272 (0.302)\tLoss 0.6056 (0.5967)\n",
            "Valid\tIter: [351/369]\tTime 0.265 (0.301)\tLoss 0.5970 (0.5966)\n",
            "Valid\tIter: [361/369]\tTime 0.248 (0.300)\tLoss 0.6092 (0.5966)\n",
            "epoch:003,valid_loss:0.59678\n",
            "acc:0.585616,F_value:0.379004, precision:0.269328,recall:0.639365,auc:0.643475,aupr:0.302466,mcc:0.168989,threadhold:0.390000\n",
            "\n",
            "Epoch: [4/10]\tIter: [1/2045]\tTime 10.038 (10.038)\tLoss 0.4973 (0.4973)\tf_max:0.722222\tp_max:0.866667\tr_max:0.787879\tt_max:0.56\n",
            "Epoch: [4/10]\tIter: [101/2045]\tTime 1.186 (1.326)\tLoss 0.3189 (0.4046)\tf_max:0.857143\tp_max:0.947368\tr_max:0.900000\tt_max:0.66\n",
            "Epoch: [4/10]\tIter: [201/2045]\tTime 1.238 (1.285)\tLoss 0.4347 (0.4020)\tf_max:0.777778\tp_max:0.933333\tr_max:0.848485\tt_max:0.56\n",
            "Epoch: [4/10]\tIter: [301/2045]\tTime 1.270 (1.271)\tLoss 0.3392 (0.3999)\tf_max:0.705882\tp_max:0.923077\tr_max:0.800000\tt_max:0.53\n",
            "Epoch: [4/10]\tIter: [401/2045]\tTime 1.189 (1.265)\tLoss 0.3258 (0.4038)\tf_max:0.727273\tp_max:1.000000\tr_max:0.842105\tt_max:0.69\n",
            "Epoch: [4/10]\tIter: [501/2045]\tTime 1.192 (1.257)\tLoss 0.2782 (0.4044)\tf_max:0.769231\tp_max:1.000000\tr_max:0.869565\tt_max:0.81\n",
            "Epoch: [4/10]\tIter: [601/2045]\tTime 1.183 (1.252)\tLoss 0.1667 (0.4023)\tf_max:0.800000\tp_max:1.000000\tr_max:0.888889\tt_max:0.47\n",
            "Epoch: [4/10]\tIter: [701/2045]\tTime 1.171 (1.249)\tLoss 0.5024 (0.4050)\tf_max:0.900000\tp_max:0.900000\tr_max:0.900000\tt_max:0.62\n",
            "Epoch: [4/10]\tIter: [801/2045]\tTime 1.206 (1.248)\tLoss 0.2931 (0.4052)\tf_max:0.818182\tp_max:0.947368\tr_max:0.878049\tt_max:0.69\n",
            "Epoch: [4/10]\tIter: [901/2045]\tTime 1.186 (1.246)\tLoss 0.3575 (0.4065)\tf_max:0.647059\tp_max:0.846154\tr_max:0.733333\tt_max:0.53\n",
            "Epoch: [4/10]\tIter: [1001/2045]\tTime 1.171 (1.245)\tLoss 0.3206 (0.4058)\tf_max:0.666667\tp_max:1.000000\tr_max:0.800000\tt_max:0.47\n",
            "Epoch: [4/10]\tIter: [1101/2045]\tTime 1.188 (1.245)\tLoss 0.4003 (0.4054)\tf_max:0.666667\tp_max:1.000000\tr_max:0.800000\tt_max:0.66\n",
            "Epoch: [4/10]\tIter: [1201/2045]\tTime 1.287 (1.244)\tLoss 0.3121 (0.4058)\tf_max:0.708333\tp_max:0.944444\tr_max:0.809524\tt_max:0.75\n",
            "Epoch: [4/10]\tIter: [1301/2045]\tTime 1.264 (1.243)\tLoss 0.3354 (0.4056)\tf_max:0.772727\tp_max:0.944444\tr_max:0.850000\tt_max:0.69\n",
            "Epoch: [4/10]\tIter: [1401/2045]\tTime 1.183 (1.242)\tLoss 0.3386 (0.4050)\tf_max:0.777778\tp_max:1.000000\tr_max:0.875000\tt_max:0.84\n",
            "Epoch: [4/10]\tIter: [1501/2045]\tTime 1.217 (1.242)\tLoss 0.3019 (0.4033)\tf_max:0.823529\tp_max:1.000000\tr_max:0.903226\tt_max:0.53\n",
            "Epoch: [4/10]\tIter: [1601/2045]\tTime 1.164 (1.241)\tLoss 0.3146 (0.4030)\tf_max:0.750000\tp_max:1.000000\tr_max:0.857143\tt_max:0.75\n",
            "Epoch: [4/10]\tIter: [1701/2045]\tTime 1.187 (1.241)\tLoss 0.2972 (0.4025)\tf_max:0.772727\tp_max:1.000000\tr_max:0.871795\tt_max:0.69\n",
            "Epoch: [4/10]\tIter: [1801/2045]\tTime 1.193 (1.240)\tLoss 0.3602 (0.4021)\tf_max:0.652174\tp_max:1.000000\tr_max:0.789474\tt_max:0.72\n",
            "Epoch: [4/10]\tIter: [1901/2045]\tTime 1.195 (1.240)\tLoss 0.3112 (0.4009)\tf_max:0.809524\tp_max:0.944444\tr_max:0.871795\tt_max:0.66\n",
            "Epoch: [4/10]\tIter: [2001/2045]\tTime 1.531 (1.240)\tLoss 0.4471 (0.4002)\tf_max:0.666667\tp_max:0.857143\tr_max:0.750000\tt_max:0.56\n",
            "Valid\tIter: [1/369]\tTime 1.952 (1.952)\tLoss 0.6469 (0.6469)\n",
            "Valid\tIter: [11/369]\tTime 0.261 (0.427)\tLoss 0.6160 (0.6002)\n",
            "Valid\tIter: [21/369]\tTime 0.277 (0.355)\tLoss 0.4929 (0.6257)\n",
            "Valid\tIter: [31/369]\tTime 0.254 (0.325)\tLoss 0.5455 (0.6169)\n",
            "Valid\tIter: [41/369]\tTime 0.263 (0.310)\tLoss 0.5914 (0.6002)\n",
            "Valid\tIter: [51/369]\tTime 0.267 (0.302)\tLoss 0.4241 (0.6102)\n",
            "Valid\tIter: [61/369]\tTime 0.267 (0.298)\tLoss 0.5255 (0.5972)\n",
            "Valid\tIter: [71/369]\tTime 0.265 (0.293)\tLoss 0.7072 (0.5979)\n",
            "Valid\tIter: [81/369]\tTime 0.263 (0.289)\tLoss 0.5289 (0.5974)\n",
            "Valid\tIter: [91/369]\tTime 0.258 (0.286)\tLoss 0.5241 (0.5931)\n",
            "Valid\tIter: [101/369]\tTime 0.260 (0.284)\tLoss 0.3954 (0.5818)\n",
            "Valid\tIter: [111/369]\tTime 0.263 (0.283)\tLoss 0.5900 (0.5808)\n",
            "Valid\tIter: [121/369]\tTime 0.263 (0.281)\tLoss 0.5417 (0.5808)\n",
            "Valid\tIter: [131/369]\tTime 0.259 (0.280)\tLoss 0.6605 (0.5831)\n",
            "Valid\tIter: [141/369]\tTime 0.260 (0.279)\tLoss 0.6383 (0.5834)\n",
            "Valid\tIter: [151/369]\tTime 0.269 (0.278)\tLoss 0.7219 (0.5873)\n",
            "Valid\tIter: [161/369]\tTime 0.263 (0.277)\tLoss 0.5250 (0.5838)\n",
            "Valid\tIter: [171/369]\tTime 0.280 (0.277)\tLoss 0.5677 (0.5858)\n",
            "Valid\tIter: [181/369]\tTime 0.260 (0.277)\tLoss 0.3859 (0.5821)\n",
            "Valid\tIter: [191/369]\tTime 0.264 (0.276)\tLoss 0.4037 (0.5810)\n",
            "Valid\tIter: [201/369]\tTime 0.280 (0.276)\tLoss 0.5304 (0.5791)\n",
            "Valid\tIter: [211/369]\tTime 0.259 (0.275)\tLoss 0.7627 (0.5779)\n",
            "Valid\tIter: [221/369]\tTime 0.272 (0.275)\tLoss 0.7584 (0.5794)\n",
            "Valid\tIter: [231/369]\tTime 0.272 (0.275)\tLoss 0.7319 (0.5804)\n",
            "Valid\tIter: [241/369]\tTime 0.271 (0.274)\tLoss 0.6578 (0.5799)\n",
            "Valid\tIter: [251/369]\tTime 0.272 (0.274)\tLoss 0.6218 (0.5807)\n",
            "Valid\tIter: [261/369]\tTime 0.290 (0.274)\tLoss 0.6005 (0.5819)\n",
            "Valid\tIter: [271/369]\tTime 0.270 (0.274)\tLoss 0.7793 (0.5836)\n",
            "Valid\tIter: [281/369]\tTime 0.279 (0.274)\tLoss 0.4858 (0.5828)\n",
            "Valid\tIter: [291/369]\tTime 0.279 (0.274)\tLoss 0.6379 (0.5815)\n",
            "Valid\tIter: [301/369]\tTime 0.261 (0.274)\tLoss 0.6543 (0.5815)\n",
            "Valid\tIter: [311/369]\tTime 0.267 (0.273)\tLoss 0.5373 (0.5824)\n",
            "Valid\tIter: [321/369]\tTime 0.269 (0.273)\tLoss 0.6744 (0.5850)\n",
            "Valid\tIter: [331/369]\tTime 0.286 (0.273)\tLoss 0.5111 (0.5843)\n",
            "Valid\tIter: [341/369]\tTime 0.258 (0.273)\tLoss 0.4689 (0.5840)\n",
            "Valid\tIter: [351/369]\tTime 0.272 (0.273)\tLoss 0.7250 (0.5837)\n",
            "Valid\tIter: [361/369]\tTime 0.256 (0.272)\tLoss 0.5059 (0.5844)\n",
            "epoch:004,valid_loss:0.58545\n",
            "acc:0.634297,F_value:0.396078, precision:0.294093,recall:0.606346,auc:0.664106,aupr:0.314963,mcc:0.200641,threadhold:0.420000\n",
            "\n",
            "new best F_value:0.396078431372549(threadhold:0.42)\n",
            "Epoch: [5/10]\tIter: [1/2045]\tTime 3.665 (3.665)\tLoss 0.3472 (0.3472)\tf_max:0.727273\tp_max:0.941176\tr_max:0.820513\tt_max:0.69\n",
            "Epoch: [5/10]\tIter: [101/2045]\tTime 1.201 (1.257)\tLoss 0.2598 (0.3317)\tf_max:0.916667\tp_max:1.000000\tr_max:0.956522\tt_max:0.75\n",
            "Epoch: [5/10]\tIter: [201/2045]\tTime 1.176 (1.239)\tLoss 0.4498 (0.3416)\tf_max:0.666667\tp_max:0.933333\tr_max:0.777778\tt_max:0.66\n",
            "Epoch: [5/10]\tIter: [301/2045]\tTime 1.240 (1.240)\tLoss 0.3664 (0.3395)\tf_max:0.785714\tp_max:0.916667\tr_max:0.846154\tt_max:0.44\n",
            "Epoch: [5/10]\tIter: [401/2045]\tTime 1.197 (1.236)\tLoss 0.4179 (0.3409)\tf_max:0.857143\tp_max:0.857143\tr_max:0.857143\tt_max:0.44\n",
            "Epoch: [5/10]\tIter: [501/2045]\tTime 1.194 (1.233)\tLoss 0.2898 (0.3443)\tf_max:0.812500\tp_max:0.928571\tr_max:0.866667\tt_max:0.50\n",
            "Epoch: [5/10]\tIter: [601/2045]\tTime 1.177 (1.231)\tLoss 0.2914 (0.3444)\tf_max:0.812500\tp_max:0.866667\tr_max:0.838710\tt_max:0.50\n",
            "Epoch: [5/10]\tIter: [701/2045]\tTime 1.198 (1.229)\tLoss 0.3044 (0.3459)\tf_max:0.588235\tp_max:0.909091\tr_max:0.714286\tt_max:0.53\n",
            "Epoch: [5/10]\tIter: [801/2045]\tTime 1.161 (1.228)\tLoss 0.2895 (0.3442)\tf_max:0.866667\tp_max:0.866667\tr_max:0.866667\tt_max:0.47\n",
            "Epoch: [5/10]\tIter: [901/2045]\tTime 1.168 (1.227)\tLoss 0.2893 (0.3455)\tf_max:0.875000\tp_max:0.933333\tr_max:0.903226\tt_max:0.50\n",
            "Epoch: [5/10]\tIter: [1001/2045]\tTime 1.231 (1.227)\tLoss 0.3034 (0.3452)\tf_max:0.777778\tp_max:0.933333\tr_max:0.848485\tt_max:0.56\n",
            "Epoch: [5/10]\tIter: [1101/2045]\tTime 1.251 (1.232)\tLoss 0.3884 (0.3457)\tf_max:0.800000\tp_max:0.800000\tr_max:0.800000\tt_max:0.62\n",
            "Epoch: [5/10]\tIter: [1201/2045]\tTime 1.193 (1.236)\tLoss 0.2081 (0.3441)\tf_max:0.842105\tp_max:0.941176\tr_max:0.888889\tt_max:0.59\n",
            "Epoch: [5/10]\tIter: [1301/2045]\tTime 1.314 (1.236)\tLoss 0.5412 (0.3443)\tf_max:0.687500\tp_max:0.687500\tr_max:0.687500\tt_max:0.50\n",
            "Epoch: [5/10]\tIter: [1401/2045]\tTime 1.457 (1.236)\tLoss 0.3967 (0.3441)\tf_max:0.625000\tp_max:0.909091\tr_max:0.740741\tt_max:0.50\n",
            "Epoch: [5/10]\tIter: [1501/2045]\tTime 1.208 (1.237)\tLoss 0.2681 (0.3439)\tf_max:0.900000\tp_max:0.900000\tr_max:0.900000\tt_max:0.62\n",
            "Epoch: [5/10]\tIter: [1601/2045]\tTime 1.161 (1.237)\tLoss 0.2692 (0.3434)\tf_max:0.894737\tp_max:0.944444\tr_max:0.918919\tt_max:0.59\n",
            "Epoch: [5/10]\tIter: [1701/2045]\tTime 1.180 (1.237)\tLoss 0.1951 (0.3431)\tf_max:0.900000\tp_max:0.900000\tr_max:0.900000\tt_max:0.31\n",
            "Epoch: [5/10]\tIter: [1801/2045]\tTime 1.192 (1.237)\tLoss 0.4544 (0.3423)\tf_max:0.789474\tp_max:0.833333\tr_max:0.810811\tt_max:0.59\n",
            "Epoch: [5/10]\tIter: [1901/2045]\tTime 1.501 (1.237)\tLoss 0.2906 (0.3410)\tf_max:0.823529\tp_max:0.875000\tr_max:0.848485\tt_max:0.53\n",
            "Epoch: [5/10]\tIter: [2001/2045]\tTime 1.206 (1.238)\tLoss 0.1697 (0.3408)\tf_max:0.894737\tp_max:1.000000\tr_max:0.944444\tt_max:0.59\n",
            "Valid\tIter: [1/369]\tTime 1.993 (1.993)\tLoss 0.6867 (0.6867)\n",
            "Valid\tIter: [11/369]\tTime 0.257 (0.441)\tLoss 0.8587 (0.6523)\n",
            "Valid\tIter: [21/369]\tTime 0.272 (0.359)\tLoss 0.7282 (0.6849)\n",
            "Valid\tIter: [31/369]\tTime 0.266 (0.331)\tLoss 0.6319 (0.6795)\n",
            "Valid\tIter: [41/369]\tTime 0.273 (0.316)\tLoss 0.6540 (0.6760)\n",
            "Valid\tIter: [51/369]\tTime 0.291 (0.308)\tLoss 0.5647 (0.6558)\n",
            "Valid\tIter: [61/369]\tTime 0.262 (0.301)\tLoss 0.6220 (0.6590)\n",
            "Valid\tIter: [71/369]\tTime 0.266 (0.296)\tLoss 0.5017 (0.6561)\n",
            "Valid\tIter: [81/369]\tTime 0.272 (0.293)\tLoss 0.9506 (0.6571)\n",
            "Valid\tIter: [91/369]\tTime 0.269 (0.291)\tLoss 0.4977 (0.6521)\n",
            "Valid\tIter: [101/369]\tTime 0.271 (0.288)\tLoss 0.7924 (0.6588)\n",
            "Valid\tIter: [111/369]\tTime 0.268 (0.287)\tLoss 0.7865 (0.6577)\n",
            "Valid\tIter: [121/369]\tTime 0.262 (0.285)\tLoss 0.5471 (0.6559)\n",
            "Valid\tIter: [131/369]\tTime 0.263 (0.284)\tLoss 0.4022 (0.6582)\n",
            "Valid\tIter: [141/369]\tTime 0.290 (0.282)\tLoss 0.6705 (0.6572)\n",
            "Valid\tIter: [151/369]\tTime 0.273 (0.282)\tLoss 0.8873 (0.6528)\n",
            "Valid\tIter: [161/369]\tTime 0.258 (0.281)\tLoss 0.7471 (0.6541)\n",
            "Valid\tIter: [171/369]\tTime 0.263 (0.280)\tLoss 0.6793 (0.6519)\n",
            "Valid\tIter: [181/369]\tTime 0.264 (0.279)\tLoss 0.6880 (0.6503)\n",
            "Valid\tIter: [191/369]\tTime 0.280 (0.279)\tLoss 1.0016 (0.6489)\n",
            "Valid\tIter: [201/369]\tTime 0.263 (0.278)\tLoss 0.7913 (0.6450)\n",
            "Valid\tIter: [211/369]\tTime 0.259 (0.277)\tLoss 0.6380 (0.6430)\n",
            "Valid\tIter: [221/369]\tTime 0.264 (0.277)\tLoss 0.5359 (0.6423)\n",
            "Valid\tIter: [231/369]\tTime 0.270 (0.277)\tLoss 0.6500 (0.6395)\n",
            "Valid\tIter: [241/369]\tTime 0.274 (0.277)\tLoss 0.5904 (0.6371)\n",
            "Valid\tIter: [251/369]\tTime 0.266 (0.276)\tLoss 0.6671 (0.6401)\n",
            "Valid\tIter: [261/369]\tTime 0.257 (0.276)\tLoss 0.3541 (0.6377)\n",
            "Valid\tIter: [271/369]\tTime 0.268 (0.276)\tLoss 0.7804 (0.6369)\n",
            "Valid\tIter: [281/369]\tTime 0.268 (0.275)\tLoss 0.6343 (0.6370)\n",
            "Valid\tIter: [291/369]\tTime 0.259 (0.275)\tLoss 0.4451 (0.6348)\n",
            "Valid\tIter: [301/369]\tTime 0.296 (0.275)\tLoss 0.7694 (0.6373)\n",
            "Valid\tIter: [311/369]\tTime 0.257 (0.321)\tLoss 0.7040 (0.6374)\n",
            "Valid\tIter: [321/369]\tTime 0.265 (0.320)\tLoss 0.6370 (0.6348)\n",
            "Valid\tIter: [331/369]\tTime 0.253 (0.318)\tLoss 0.6338 (0.6332)\n",
            "Valid\tIter: [341/369]\tTime 0.254 (0.316)\tLoss 0.6444 (0.6342)\n",
            "Valid\tIter: [351/369]\tTime 0.260 (0.315)\tLoss 0.5211 (0.6338)\n",
            "Valid\tIter: [361/369]\tTime 0.254 (0.313)\tLoss 0.4897 (0.6319)\n",
            "epoch:005,valid_loss:0.63153\n",
            "acc:0.573658,F_value:0.380377, precision:0.266909,recall:0.661664,auc:0.644248,aupr:0.301686,mcc:0.170216,threadhold:0.230000\n",
            "\n",
            "Epoch: [6/10]\tIter: [1/2045]\tTime 3.321 (3.321)\tLoss 0.2291 (0.2291)\tf_max:0.952381\tp_max:0.952381\tr_max:0.952381\tt_max:0.66\n",
            "Epoch: [6/10]\tIter: [101/2045]\tTime 1.195 (1.249)\tLoss 0.3479 (0.2798)\tf_max:0.941176\tp_max:0.842105\tr_max:0.888889\tt_max:0.53\n",
            "Epoch: [6/10]\tIter: [201/2045]\tTime 1.247 (1.243)\tLoss 0.1967 (0.2755)\tf_max:0.941176\tp_max:0.941176\tr_max:0.941176\tt_max:0.53\n",
            "Epoch: [6/10]\tIter: [301/2045]\tTime 1.208 (1.246)\tLoss 0.2121 (0.2690)\tf_max:0.863636\tp_max:0.950000\tr_max:0.904762\tt_max:0.69\n",
            "Epoch: [6/10]\tIter: [401/2045]\tTime 1.408 (1.247)\tLoss 0.3850 (0.2665)\tf_max:0.818182\tp_max:0.900000\tr_max:0.857143\tt_max:0.69\n",
            "Epoch: [6/10]\tIter: [501/2045]\tTime 1.350 (1.243)\tLoss 0.2209 (0.2664)\tf_max:0.823529\tp_max:1.000000\tr_max:0.903226\tt_max:0.53\n",
            "Epoch: [6/10]\tIter: [601/2045]\tTime 1.271 (1.241)\tLoss 0.2259 (0.2687)\tf_max:0.875000\tp_max:1.000000\tr_max:0.933333\tt_max:0.50\n",
            "Epoch: [6/10]\tIter: [701/2045]\tTime 1.218 (1.240)\tLoss 0.3498 (0.2698)\tf_max:0.846154\tp_max:0.846154\tr_max:0.846154\tt_max:0.41\n",
            "Epoch: [6/10]\tIter: [801/2045]\tTime 1.249 (1.238)\tLoss 0.5038 (0.2717)\tf_max:0.733333\tp_max:0.733333\tr_max:0.733333\tt_max:0.47\n",
            "Epoch: [6/10]\tIter: [901/2045]\tTime 1.174 (1.236)\tLoss 0.2444 (0.2746)\tf_max:0.950000\tp_max:0.950000\tr_max:0.950000\tt_max:0.62\n",
            "Epoch: [6/10]\tIter: [1001/2045]\tTime 1.191 (1.235)\tLoss 0.1832 (0.2739)\tf_max:0.947368\tp_max:1.000000\tr_max:0.972973\tt_max:0.59\n",
            "Epoch: [6/10]\tIter: [1101/2045]\tTime 1.203 (1.235)\tLoss 0.2410 (0.2733)\tf_max:0.900000\tp_max:0.900000\tr_max:0.900000\tt_max:0.62\n",
            "Epoch: [6/10]\tIter: [1201/2045]\tTime 1.204 (1.234)\tLoss 0.3037 (0.2741)\tf_max:0.823529\tp_max:0.933333\tr_max:0.875000\tt_max:0.53\n",
            "Epoch: [6/10]\tIter: [1301/2045]\tTime 1.180 (1.234)\tLoss 0.2748 (0.2734)\tf_max:0.842105\tp_max:1.000000\tr_max:0.914286\tt_max:0.59\n",
            "Epoch: [6/10]\tIter: [1401/2045]\tTime 1.190 (1.233)\tLoss 0.2850 (0.2724)\tf_max:0.850000\tp_max:0.944444\tr_max:0.894737\tt_max:0.62\n",
            "Epoch: [6/10]\tIter: [1501/2045]\tTime 1.208 (1.234)\tLoss 0.2495 (0.2717)\tf_max:0.869565\tp_max:0.952381\tr_max:0.909091\tt_max:0.72\n",
            "Epoch: [6/10]\tIter: [1601/2045]\tTime 1.415 (1.235)\tLoss 0.1570 (0.2726)\tf_max:0.950000\tp_max:0.950000\tr_max:0.950000\tt_max:0.62\n",
            "Epoch: [6/10]\tIter: [1701/2045]\tTime 1.200 (1.237)\tLoss 0.2415 (0.2728)\tf_max:0.800000\tp_max:1.000000\tr_max:0.888889\tt_max:0.62\n",
            "Epoch: [6/10]\tIter: [1801/2045]\tTime 1.215 (1.238)\tLoss 0.4252 (0.2731)\tf_max:0.750000\tp_max:0.800000\tr_max:0.774194\tt_max:0.50\n",
            "Epoch: [6/10]\tIter: [1901/2045]\tTime 1.212 (1.239)\tLoss 0.3202 (0.2728)\tf_max:0.833333\tp_max:0.714286\tr_max:0.769231\tt_max:0.38\n",
            "Epoch: [6/10]\tIter: [2001/2045]\tTime 1.201 (1.241)\tLoss 0.2981 (0.2717)\tf_max:0.857143\tp_max:1.000000\tr_max:0.923077\tt_max:0.66\n",
            "Valid\tIter: [1/369]\tTime 1.921 (1.921)\tLoss 0.7716 (0.7716)\n",
            "Valid\tIter: [11/369]\tTime 0.276 (0.443)\tLoss 0.5845 (0.5980)\n",
            "Valid\tIter: [21/369]\tTime 0.268 (0.360)\tLoss 0.6713 (0.6569)\n",
            "Valid\tIter: [31/369]\tTime 0.275 (0.334)\tLoss 1.1202 (0.6793)\n",
            "Valid\tIter: [41/369]\tTime 0.259 (0.319)\tLoss 0.6683 (0.6901)\n",
            "Valid\tIter: [51/369]\tTime 0.267 (0.312)\tLoss 0.6975 (0.6977)\n",
            "Valid\tIter: [61/369]\tTime 0.271 (0.306)\tLoss 0.6561 (0.7209)\n",
            "Valid\tIter: [71/369]\tTime 0.292 (0.302)\tLoss 1.0024 (0.7156)\n",
            "Valid\tIter: [81/369]\tTime 0.268 (0.299)\tLoss 0.9202 (0.7208)\n",
            "Valid\tIter: [91/369]\tTime 0.266 (0.295)\tLoss 0.7003 (0.7251)\n",
            "Valid\tIter: [101/369]\tTime 0.299 (0.294)\tLoss 0.7007 (0.7144)\n",
            "Valid\tIter: [111/369]\tTime 0.289 (0.292)\tLoss 0.5158 (0.7097)\n",
            "Valid\tIter: [121/369]\tTime 0.281 (0.369)\tLoss 0.8729 (0.7044)\n",
            "Valid\tIter: [131/369]\tTime 0.275 (0.362)\tLoss 0.5010 (0.7083)\n",
            "Valid\tIter: [141/369]\tTime 0.266 (0.355)\tLoss 0.6124 (0.7104)\n",
            "Valid\tIter: [151/369]\tTime 0.261 (0.350)\tLoss 0.8003 (0.7119)\n",
            "Valid\tIter: [161/369]\tTime 0.274 (0.345)\tLoss 0.9427 (0.7115)\n",
            "Valid\tIter: [171/369]\tTime 0.269 (0.341)\tLoss 0.5472 (0.7102)\n",
            "Valid\tIter: [181/369]\tTime 0.274 (0.337)\tLoss 0.7759 (0.7125)\n",
            "Valid\tIter: [191/369]\tTime 0.267 (0.334)\tLoss 0.6821 (0.7145)\n",
            "Valid\tIter: [201/369]\tTime 0.275 (0.331)\tLoss 0.6834 (0.7134)\n",
            "Valid\tIter: [211/369]\tTime 0.283 (0.328)\tLoss 0.5567 (0.7097)\n",
            "Valid\tIter: [221/369]\tTime 0.293 (0.326)\tLoss 0.6463 (0.7115)\n",
            "Valid\tIter: [231/369]\tTime 0.266 (0.323)\tLoss 0.4405 (0.7083)\n",
            "Valid\tIter: [241/369]\tTime 0.273 (0.321)\tLoss 0.5656 (0.7096)\n",
            "Valid\tIter: [251/369]\tTime 0.272 (0.319)\tLoss 0.7062 (0.7102)\n",
            "Valid\tIter: [261/369]\tTime 0.265 (0.317)\tLoss 0.7416 (0.7084)\n",
            "Valid\tIter: [271/369]\tTime 0.273 (0.316)\tLoss 0.5436 (0.7095)\n",
            "Valid\tIter: [281/369]\tTime 0.267 (0.314)\tLoss 0.8975 (0.7105)\n",
            "Valid\tIter: [291/369]\tTime 0.293 (0.313)\tLoss 1.0361 (0.7130)\n",
            "Valid\tIter: [301/369]\tTime 0.265 (0.311)\tLoss 0.4936 (0.7115)\n",
            "Valid\tIter: [311/369]\tTime 0.271 (0.310)\tLoss 0.7299 (0.7131)\n",
            "Valid\tIter: [321/369]\tTime 0.268 (0.309)\tLoss 0.7475 (0.7131)\n",
            "Valid\tIter: [331/369]\tTime 0.296 (0.308)\tLoss 0.3766 (0.7109)\n",
            "Valid\tIter: [341/369]\tTime 0.274 (0.307)\tLoss 0.7560 (0.7128)\n",
            "Valid\tIter: [351/369]\tTime 0.289 (0.306)\tLoss 0.5965 (0.7132)\n",
            "Valid\tIter: [361/369]\tTime 0.252 (0.305)\tLoss 0.6184 (0.7157)\n",
            "epoch:006,valid_loss:0.71685\n",
            "acc:0.580612,F_value:0.382261, precision:0.269699,recall:0.656089,auc:0.643572,aupr:0.292020,mcc:0.173868,threadhold:0.220000\n",
            "\n",
            "Epoch: [7/10]\tIter: [1/2045]\tTime 10.104 (10.104)\tLoss 0.2934 (0.2934)\tf_max:0.777778\tp_max:0.875000\tr_max:0.823529\tt_max:0.56\n",
            "Epoch: [7/10]\tIter: [101/2045]\tTime 1.184 (1.337)\tLoss 0.1034 (0.1934)\tf_max:0.875000\tp_max:1.000000\tr_max:0.933333\tt_max:0.50\n",
            "Epoch: [7/10]\tIter: [201/2045]\tTime 1.200 (1.291)\tLoss 0.1688 (0.1989)\tf_max:0.866667\tp_max:0.928571\tr_max:0.896552\tt_max:0.47\n",
            "Epoch: [7/10]\tIter: [301/2045]\tTime 1.517 (1.276)\tLoss 0.3051 (0.2019)\tf_max:0.857143\tp_max:0.800000\tr_max:0.827586\tt_max:0.44\n",
            "Epoch: [7/10]\tIter: [401/2045]\tTime 1.169 (1.265)\tLoss 0.0998 (0.2021)\tf_max:0.933333\tp_max:1.000000\tr_max:0.965517\tt_max:0.47\n",
            "Epoch: [7/10]\tIter: [501/2045]\tTime 1.218 (1.260)\tLoss 0.1776 (0.2026)\tf_max:0.941176\tp_max:0.941176\tr_max:0.941176\tt_max:0.53\n",
            "Epoch: [7/10]\tIter: [601/2045]\tTime 1.205 (1.256)\tLoss 0.1668 (0.2054)\tf_max:0.937500\tp_max:1.000000\tr_max:0.967742\tt_max:0.50\n",
            "Epoch: [7/10]\tIter: [701/2045]\tTime 1.238 (1.257)\tLoss 0.2638 (0.2062)\tf_max:0.800000\tp_max:1.000000\tr_max:0.888889\tt_max:0.62\n",
            "Epoch: [7/10]\tIter: [801/2045]\tTime 1.350 (1.257)\tLoss 0.2923 (0.2085)\tf_max:0.857143\tp_max:1.000000\tr_max:0.923077\tt_max:0.66\n",
            "Epoch: [7/10]\tIter: [901/2045]\tTime 1.210 (1.255)\tLoss 0.3667 (0.2107)\tf_max:1.000000\tp_max:0.700000\tr_max:0.823529\tt_max:0.44\n",
            "Epoch: [7/10]\tIter: [1001/2045]\tTime 1.217 (1.256)\tLoss 0.0674 (0.2099)\tf_max:0.941176\tp_max:1.000000\tr_max:0.969697\tt_max:0.53\n",
            "Epoch: [7/10]\tIter: [1101/2045]\tTime 1.214 (1.256)\tLoss 0.0869 (0.2095)\tf_max:1.000000\tp_max:1.000000\tr_max:1.000000\tt_max:0.66\n",
            "Epoch: [7/10]\tIter: [1201/2045]\tTime 1.407 (1.256)\tLoss 0.2628 (0.2100)\tf_max:0.818182\tp_max:1.000000\tr_max:0.900000\tt_max:0.69\n",
            "Epoch: [7/10]\tIter: [1301/2045]\tTime 1.448 (1.255)\tLoss 0.2324 (0.2103)\tf_max:0.714286\tp_max:0.909091\tr_max:0.800000\tt_max:0.44\n",
            "Epoch: [7/10]\tIter: [1401/2045]\tTime 1.203 (1.255)\tLoss 0.2246 (0.2110)\tf_max:0.833333\tp_max:0.714286\tr_max:0.769231\tt_max:0.38\n",
            "Epoch: [7/10]\tIter: [1501/2045]\tTime 1.200 (1.255)\tLoss 0.1500 (0.2111)\tf_max:0.937500\tp_max:0.937500\tr_max:0.937500\tt_max:0.50\n",
            "Epoch: [7/10]\tIter: [1601/2045]\tTime 1.345 (1.255)\tLoss 0.1355 (0.2116)\tf_max:0.947368\tp_max:0.900000\tr_max:0.923077\tt_max:0.59\n",
            "Epoch: [7/10]\tIter: [1701/2045]\tTime 1.215 (1.255)\tLoss 0.2098 (0.2116)\tf_max:0.842105\tp_max:0.941176\tr_max:0.888889\tt_max:0.59\n",
            "Epoch: [7/10]\tIter: [1801/2045]\tTime 1.255 (1.256)\tLoss 0.4337 (0.2120)\tf_max:0.900000\tp_max:0.818182\tr_max:0.857143\tt_max:0.62\n",
            "Epoch: [7/10]\tIter: [1901/2045]\tTime 1.275 (1.258)\tLoss 0.2221 (0.2114)\tf_max:0.900000\tp_max:1.000000\tr_max:0.947368\tt_max:0.62\n",
            "Epoch: [7/10]\tIter: [2001/2045]\tTime 1.546 (1.259)\tLoss 0.1691 (0.2112)\tf_max:0.846154\tp_max:0.846154\tr_max:0.846154\tt_max:0.41\n",
            "Valid\tIter: [1/369]\tTime 1.913 (1.913)\tLoss 0.6620 (0.6620)\n",
            "Valid\tIter: [11/369]\tTime 0.298 (0.435)\tLoss 0.9861 (0.7142)\n",
            "Valid\tIter: [21/369]\tTime 0.267 (0.361)\tLoss 0.4212 (0.7323)\n",
            "Valid\tIter: [31/369]\tTime 0.276 (0.334)\tLoss 0.3669 (0.6999)\n",
            "Valid\tIter: [41/369]\tTime 0.272 (0.318)\tLoss 0.8295 (0.7076)\n",
            "Valid\tIter: [51/369]\tTime 0.276 (0.310)\tLoss 0.7170 (0.7085)\n",
            "Valid\tIter: [61/369]\tTime 0.271 (0.304)\tLoss 0.4942 (0.7340)\n",
            "Valid\tIter: [71/369]\tTime 0.268 (0.299)\tLoss 0.8396 (0.7436)\n",
            "Valid\tIter: [81/369]\tTime 0.271 (0.295)\tLoss 0.5411 (0.7480)\n",
            "Valid\tIter: [91/369]\tTime 0.270 (0.292)\tLoss 0.7278 (0.7302)\n",
            "Valid\tIter: [101/369]\tTime 0.272 (0.290)\tLoss 0.6666 (0.7302)\n",
            "Valid\tIter: [111/369]\tTime 0.279 (0.288)\tLoss 0.8688 (0.7435)\n",
            "Valid\tIter: [121/369]\tTime 0.280 (0.286)\tLoss 0.6910 (0.7451)\n",
            "Valid\tIter: [131/369]\tTime 0.265 (0.285)\tLoss 0.8443 (0.7456)\n",
            "Valid\tIter: [141/369]\tTime 0.267 (0.284)\tLoss 0.8042 (0.7456)\n",
            "Valid\tIter: [151/369]\tTime 0.291 (0.284)\tLoss 0.8978 (0.7503)\n",
            "Valid\tIter: [161/369]\tTime 0.261 (0.283)\tLoss 0.8811 (0.7578)\n",
            "Valid\tIter: [171/369]\tTime 0.259 (0.283)\tLoss 0.8765 (0.7614)\n",
            "Valid\tIter: [181/369]\tTime 0.264 (0.282)\tLoss 0.4921 (0.7613)\n",
            "Valid\tIter: [191/369]\tTime 0.275 (0.281)\tLoss 0.7734 (0.7623)\n",
            "Valid\tIter: [201/369]\tTime 0.260 (0.281)\tLoss 1.0500 (0.7655)\n",
            "Valid\tIter: [211/369]\tTime 0.264 (0.280)\tLoss 0.5585 (0.7624)\n",
            "Valid\tIter: [221/369]\tTime 0.273 (0.280)\tLoss 0.6155 (0.7576)\n",
            "Valid\tIter: [231/369]\tTime 0.257 (0.279)\tLoss 0.8316 (0.7610)\n",
            "Valid\tIter: [241/369]\tTime 0.286 (0.279)\tLoss 0.6109 (0.7536)\n",
            "Valid\tIter: [251/369]\tTime 0.296 (0.279)\tLoss 1.0523 (0.7556)\n",
            "Valid\tIter: [261/369]\tTime 0.263 (0.278)\tLoss 0.8890 (0.7612)\n",
            "Valid\tIter: [271/369]\tTime 0.263 (0.278)\tLoss 0.6588 (0.7615)\n",
            "Valid\tIter: [281/369]\tTime 0.277 (0.278)\tLoss 0.9081 (0.7641)\n",
            "Valid\tIter: [291/369]\tTime 0.266 (0.278)\tLoss 0.3312 (0.7639)\n",
            "Valid\tIter: [301/369]\tTime 0.270 (0.278)\tLoss 0.6598 (0.7644)\n",
            "Valid\tIter: [311/369]\tTime 0.260 (0.277)\tLoss 0.6156 (0.7661)\n",
            "Valid\tIter: [321/369]\tTime 0.271 (0.277)\tLoss 0.9000 (0.7646)\n",
            "Valid\tIter: [331/369]\tTime 0.267 (0.277)\tLoss 0.8795 (0.7620)\n",
            "Valid\tIter: [341/369]\tTime 0.259 (0.277)\tLoss 1.3002 (0.7625)\n",
            "Valid\tIter: [351/369]\tTime 0.260 (0.276)\tLoss 0.8437 (0.7629)\n",
            "Valid\tIter: [361/369]\tTime 0.248 (0.276)\tLoss 0.7178 (0.7635)\n",
            "epoch:007,valid_loss:0.76925\n",
            "acc:0.583750,F_value:0.384500, precision:0.271712,recall:0.657376,auc:0.646170,aupr:0.292790,mcc:0.177797,threadhold:0.110000\n",
            "\n",
            "Epoch: [8/10]\tIter: [1/2045]\tTime 3.667 (3.667)\tLoss 0.1585 (0.1585)\tf_max:1.000000\tp_max:0.875000\tr_max:0.933333\tt_max:0.44\n",
            "Epoch: [8/10]\tIter: [101/2045]\tTime 1.210 (1.273)\tLoss 0.1368 (0.1557)\tf_max:0.900000\tp_max:1.000000\tr_max:0.947368\tt_max:0.62\n",
            "Epoch: [8/10]\tIter: [201/2045]\tTime 1.212 (1.267)\tLoss 0.1919 (0.1502)\tf_max:1.000000\tp_max:0.882353\tr_max:0.937500\tt_max:0.47\n",
            "Epoch: [8/10]\tIter: [301/2045]\tTime 1.431 (1.261)\tLoss 0.0786 (0.1523)\tf_max:0.954545\tp_max:1.000000\tr_max:0.976744\tt_max:0.69\n",
            "Epoch: [8/10]\tIter: [401/2045]\tTime 1.303 (1.256)\tLoss 0.0620 (0.1530)\tf_max:1.000000\tp_max:1.000000\tr_max:1.000000\tt_max:0.44\n",
            "Epoch: [8/10]\tIter: [501/2045]\tTime 1.217 (1.256)\tLoss 0.1650 (0.1531)\tf_max:0.866667\tp_max:0.928571\tr_max:0.896552\tt_max:0.47\n",
            "Epoch: [8/10]\tIter: [601/2045]\tTime 1.212 (1.254)\tLoss 0.1218 (0.1578)\tf_max:0.850000\tp_max:1.000000\tr_max:0.918919\tt_max:0.62\n",
            "Epoch: [8/10]\tIter: [701/2045]\tTime 1.194 (1.252)\tLoss 0.2174 (0.1597)\tf_max:0.777778\tp_max:1.000000\tr_max:0.875000\tt_max:0.56\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c65c873c5200>\u001b[0m in \u001b[0;36m<cell line: 378>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         \u001b[0mdemo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mratio_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-c65c873c5200>\u001b[0m in \u001b[0;36mdemo\u001b[0;34m(train_data, save, train_num, ratio, window_size, splite_rate, efficient, epochs, seed, pretrained_result)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m     train(train_data,model=model, train_data_set=train_dataSet, save=save,\n\u001b[0m\u001b[1;32m    374\u001b[0m           \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m           train_file=train_list_file)\n",
            "\u001b[0;32m<ipython-input-6-c65c873c5200>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(class_tag, model, train_data_set, save, n_epochs, batch_size, lr, wd, momentum, seed, num, train_file)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             _, train_loss = train_epoch(\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_wrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-c65c873c5200>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, loader, optimizer, epoch, all_epochs, print_freq)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;31m# compute gradient and do SGD step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mdynamo_config_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m                 \u001b[0mset_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    818\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mset_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cibHj5Q4laz4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cibHj5Q4laz4",
        "outputId": "416d73b0-2ddd-4b06-d64f-e4ade3c51179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7355610211178017\n",
            "Precision: 0.3417874396135266\n",
            "Recall: 0.36406518010291594\n",
            "MCC: 0.1867780145723312\n",
            "Confusion Matrix:\n",
            "[[7824 1635]\n",
            " [1483  849]]\n",
            "F1-score: 0.35257475083056483\n"
          ]
        }
      ],
      "source": [
        "#XG BOOST\n",
        "import xgboost as xgb\n",
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, matthews_corrcoef, confusion_matrix,roc_auc_score, average_precision_score\n",
        "from imblearn.over_sampling import SMOTE,SMOTENC,BorderlineSMOTE,ADASYN\n",
        "\n",
        "# Load the data array\n",
        "data_file = 'smote_data.pickle'\n",
        "with open(data_file, 'rb') as fp:\n",
        "    train_data = pickle.load(fp)\n",
        "\n",
        "# Check if all tuples in data_array have consistent lengths\n",
        "with open('test_data.pickle', 'rb') as fp:\n",
        "    test_data = pickle.load(fp)\n",
        "\n",
        "train_features = train_data[\"train_features\"]\n",
        "train_labels = train_data[\"train_labels\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Extract features and labels for test set\n",
        "test_features = test_data[\"test_features\"]\n",
        "test_labels =test_data[\"test_labels\"]\n",
        "# Convert data to xgboost DMatrix\n",
        "train_features = xgb.DMatrix(train_features, label=train_labels)\n",
        "test_features = xgb.DMatrix(test_features, label=test_labels)\n",
        "\n",
        "# Set XGBoost parameters\n",
        "params = {\n",
        "    'objective': 'binary:logistic',  # for binary classification\n",
        "    'max_depth': 9,\n",
        "    'learning_rate': 0.1,\n",
        "    'min_child_weight':5,\n",
        "    'eval_metric': 'logloss'\n",
        "}\n",
        "\n",
        "num_round = 80  # Number of boosting rounds\n",
        "\n",
        "# Train the XGBoost model\n",
        "XGBModel = xgb.train(params, train_features, num_round)\n",
        "\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = XGBModel.predict(test_features)\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_labels, y_pred_binary)\n",
        "precision = precision_score(test_labels, y_pred_binary)\n",
        "recall = recall_score(test_labels, y_pred_binary)\n",
        "mcc = matthews_corrcoef(test_labels, y_pred_binary)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "# Print confusion matrix\n",
        "conf_matrix = confusion_matrix(test_labels, y_pred_binary)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "\n",
        "auc = roc_auc_score(test_labels, y_pred)\n",
        "\n",
        "# Calculate AUPR\n",
        "aupr = average_precision_score(test_labels, y_pred)\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Calculate F1-score\n",
        "f1 = f1_score(test_labels, y_pred_binary)\n",
        "\n",
        "print(f\"F1-score: {f1}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}